{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "import copy\n",
    "import pandas as pd\n",
    "from pandas import read_csv\n",
    "import seaborn as sns\n",
    "import cv2\n",
    "import xgboost as xgb\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sqlalchemy import create_engine\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import string\n",
    "#from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as dsets\n",
    "from sklearn.decomposition import PCA,TruncatedSVD, IncrementalPCA\n",
    "from scipy.sparse import random as sparse_random\n",
    "from sklearn.random_projection import sparse_random_matrix\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_drive = './5g_data/5G-production-dataset/5G-production-dataset/Amazon_Prime/Driving/animated-AdventureTime/B_2019.11.28_07.27.57.csv'#'AI/Advertising Dataset.csv'#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_static = './5g_data/5G-production-dataset/5G-production-dataset/Amazon_Prime/Static/animated-Ninjago/B_2020.01.06_09.55.13.csv'#'AI/Advertising Dataset.csv'#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                Timestamp  Longitude   Latitude  Speed Operatorname  CellID  \\\n",
      "0     2019.11.28_07.27.57  -8.388193  51.935608      0            B      12   \n",
      "1     2019.11.28_07.27.57  -8.388269  51.935542      1            B      12   \n",
      "2     2019.11.28_07.27.58  -8.388269  51.935542      1            B      12   \n",
      "3     2019.11.28_07.27.59  -8.388269  51.935542      1            B      12   \n",
      "4     2019.11.28_07.28.00  -8.388269  51.935542      1            B      12   \n",
      "...                   ...        ...        ...    ...          ...     ...   \n",
      "1893  2019.11.28_08.01.59  -8.483033  51.898677     24            B      11   \n",
      "1894  2019.11.28_08.02.00  -8.483033  51.898677     24            B      11   \n",
      "1895  2019.11.28_08.02.01  -8.483033  51.898677     24            B      11   \n",
      "1896  2019.11.28_08.02.02  -8.483033  51.898677     24            B      11   \n",
      "1897  2019.11.28_08.02.03  -8.483033  51.898677     24            B      11   \n",
      "\n",
      "     NetworkMode  RSRP  RSRQ   SNR  ... PINGMIN PINGMAX  PINGSTDEV  PINGLOSS  \\\n",
      "0             5G  -102   -10   8.0  ...       -       -          -         -   \n",
      "1             5G  -102   -10   8.0  ...       -       -          -         -   \n",
      "2             5G  -102   -10   8.0  ...       -       -          -         -   \n",
      "3             5G  -102   -10   3.0  ...       -       -          -         -   \n",
      "4             5G  -102   -10   3.0  ...       -       -          -         -   \n",
      "...          ...   ...   ...   ...  ...     ...     ...        ...       ...   \n",
      "1893          5G   -90   -11  -1.0  ...       -       -          -         -   \n",
      "1894          5G   -93   -12  -1.0  ...       -       -          -         -   \n",
      "1895          5G   -93   -12  -1.0  ...       -       -          -         -   \n",
      "1896          5G   -90   -14   1.0  ...       -       -          -         -   \n",
      "1897          5G   -90   -14   1.0  ...       -       -          -         -   \n",
      "\n",
      "     CELLHEX NODEHEX LACHEX RAWCELLID NRxRSRP NRxRSRQ  \n",
      "0          C    A81B   9CBA  11016972  -102.0    -1.0  \n",
      "1          C    A81B   9CBA  11016972  -102.0    -1.0  \n",
      "2          C    A81B   9CBA  11016972  -102.0    -1.0  \n",
      "3          C    A81B   9CBA  11016972  -101.0    -3.0  \n",
      "4          C    A81B   9CBA  11016972  -101.0    -3.0  \n",
      "...      ...     ...    ...       ...     ...     ...  \n",
      "1893       B    A9AA   9CBA  11119115   -83.0    -3.0  \n",
      "1894       B    A9AA   9CBA  11119115   -84.0    -2.0  \n",
      "1895       B    A9AA   9CBA  11119115   -84.0    -2.0  \n",
      "1896       B    A9AA   9CBA  11119115   -83.0    -2.0  \n",
      "1897       B    A9AA   9CBA  11119115   -83.0    -2.0  \n",
      "\n",
      "[1898 rows x 26 columns]\n"
     ]
    }
   ],
   "source": [
    "print(read_csv(file_drive))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = read_csv(file_drive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Speed</th>\n",
       "      <th>Operatorname</th>\n",
       "      <th>CellID</th>\n",
       "      <th>NetworkMode</th>\n",
       "      <th>RSRP</th>\n",
       "      <th>RSRQ</th>\n",
       "      <th>SNR</th>\n",
       "      <th>...</th>\n",
       "      <th>PINGMIN</th>\n",
       "      <th>PINGMAX</th>\n",
       "      <th>PINGSTDEV</th>\n",
       "      <th>PINGLOSS</th>\n",
       "      <th>CELLHEX</th>\n",
       "      <th>NODEHEX</th>\n",
       "      <th>LACHEX</th>\n",
       "      <th>RAWCELLID</th>\n",
       "      <th>NRxRSRP</th>\n",
       "      <th>NRxRSRQ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019.11.28_07.27.57</td>\n",
       "      <td>-8.388193</td>\n",
       "      <td>51.935608</td>\n",
       "      <td>0</td>\n",
       "      <td>B</td>\n",
       "      <td>12</td>\n",
       "      <td>5G</td>\n",
       "      <td>-102</td>\n",
       "      <td>-10</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>C</td>\n",
       "      <td>A81B</td>\n",
       "      <td>9CBA</td>\n",
       "      <td>11016972</td>\n",
       "      <td>-102.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019.11.28_07.27.57</td>\n",
       "      <td>-8.388269</td>\n",
       "      <td>51.935542</td>\n",
       "      <td>1</td>\n",
       "      <td>B</td>\n",
       "      <td>12</td>\n",
       "      <td>5G</td>\n",
       "      <td>-102</td>\n",
       "      <td>-10</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>C</td>\n",
       "      <td>A81B</td>\n",
       "      <td>9CBA</td>\n",
       "      <td>11016972</td>\n",
       "      <td>-102.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019.11.28_07.27.58</td>\n",
       "      <td>-8.388269</td>\n",
       "      <td>51.935542</td>\n",
       "      <td>1</td>\n",
       "      <td>B</td>\n",
       "      <td>12</td>\n",
       "      <td>5G</td>\n",
       "      <td>-102</td>\n",
       "      <td>-10</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>C</td>\n",
       "      <td>A81B</td>\n",
       "      <td>9CBA</td>\n",
       "      <td>11016972</td>\n",
       "      <td>-102.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019.11.28_07.27.59</td>\n",
       "      <td>-8.388269</td>\n",
       "      <td>51.935542</td>\n",
       "      <td>1</td>\n",
       "      <td>B</td>\n",
       "      <td>12</td>\n",
       "      <td>5G</td>\n",
       "      <td>-102</td>\n",
       "      <td>-10</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>C</td>\n",
       "      <td>A81B</td>\n",
       "      <td>9CBA</td>\n",
       "      <td>11016972</td>\n",
       "      <td>-101.0</td>\n",
       "      <td>-3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019.11.28_07.28.00</td>\n",
       "      <td>-8.388269</td>\n",
       "      <td>51.935542</td>\n",
       "      <td>1</td>\n",
       "      <td>B</td>\n",
       "      <td>12</td>\n",
       "      <td>5G</td>\n",
       "      <td>-102</td>\n",
       "      <td>-10</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>C</td>\n",
       "      <td>A81B</td>\n",
       "      <td>9CBA</td>\n",
       "      <td>11016972</td>\n",
       "      <td>-101.0</td>\n",
       "      <td>-3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1893</th>\n",
       "      <td>2019.11.28_08.01.59</td>\n",
       "      <td>-8.483033</td>\n",
       "      <td>51.898677</td>\n",
       "      <td>24</td>\n",
       "      <td>B</td>\n",
       "      <td>11</td>\n",
       "      <td>5G</td>\n",
       "      <td>-90</td>\n",
       "      <td>-11</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>B</td>\n",
       "      <td>A9AA</td>\n",
       "      <td>9CBA</td>\n",
       "      <td>11119115</td>\n",
       "      <td>-83.0</td>\n",
       "      <td>-3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1894</th>\n",
       "      <td>2019.11.28_08.02.00</td>\n",
       "      <td>-8.483033</td>\n",
       "      <td>51.898677</td>\n",
       "      <td>24</td>\n",
       "      <td>B</td>\n",
       "      <td>11</td>\n",
       "      <td>5G</td>\n",
       "      <td>-93</td>\n",
       "      <td>-12</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>B</td>\n",
       "      <td>A9AA</td>\n",
       "      <td>9CBA</td>\n",
       "      <td>11119115</td>\n",
       "      <td>-84.0</td>\n",
       "      <td>-2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1895</th>\n",
       "      <td>2019.11.28_08.02.01</td>\n",
       "      <td>-8.483033</td>\n",
       "      <td>51.898677</td>\n",
       "      <td>24</td>\n",
       "      <td>B</td>\n",
       "      <td>11</td>\n",
       "      <td>5G</td>\n",
       "      <td>-93</td>\n",
       "      <td>-12</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>B</td>\n",
       "      <td>A9AA</td>\n",
       "      <td>9CBA</td>\n",
       "      <td>11119115</td>\n",
       "      <td>-84.0</td>\n",
       "      <td>-2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1896</th>\n",
       "      <td>2019.11.28_08.02.02</td>\n",
       "      <td>-8.483033</td>\n",
       "      <td>51.898677</td>\n",
       "      <td>24</td>\n",
       "      <td>B</td>\n",
       "      <td>11</td>\n",
       "      <td>5G</td>\n",
       "      <td>-90</td>\n",
       "      <td>-14</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>B</td>\n",
       "      <td>A9AA</td>\n",
       "      <td>9CBA</td>\n",
       "      <td>11119115</td>\n",
       "      <td>-83.0</td>\n",
       "      <td>-2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1897</th>\n",
       "      <td>2019.11.28_08.02.03</td>\n",
       "      <td>-8.483033</td>\n",
       "      <td>51.898677</td>\n",
       "      <td>24</td>\n",
       "      <td>B</td>\n",
       "      <td>11</td>\n",
       "      <td>5G</td>\n",
       "      <td>-90</td>\n",
       "      <td>-14</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>B</td>\n",
       "      <td>A9AA</td>\n",
       "      <td>9CBA</td>\n",
       "      <td>11119115</td>\n",
       "      <td>-83.0</td>\n",
       "      <td>-2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1898 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Timestamp  Longitude   Latitude  Speed Operatorname  CellID  \\\n",
       "0     2019.11.28_07.27.57  -8.388193  51.935608      0            B      12   \n",
       "1     2019.11.28_07.27.57  -8.388269  51.935542      1            B      12   \n",
       "2     2019.11.28_07.27.58  -8.388269  51.935542      1            B      12   \n",
       "3     2019.11.28_07.27.59  -8.388269  51.935542      1            B      12   \n",
       "4     2019.11.28_07.28.00  -8.388269  51.935542      1            B      12   \n",
       "...                   ...        ...        ...    ...          ...     ...   \n",
       "1893  2019.11.28_08.01.59  -8.483033  51.898677     24            B      11   \n",
       "1894  2019.11.28_08.02.00  -8.483033  51.898677     24            B      11   \n",
       "1895  2019.11.28_08.02.01  -8.483033  51.898677     24            B      11   \n",
       "1896  2019.11.28_08.02.02  -8.483033  51.898677     24            B      11   \n",
       "1897  2019.11.28_08.02.03  -8.483033  51.898677     24            B      11   \n",
       "\n",
       "     NetworkMode  RSRP  RSRQ   SNR  ... PINGMIN PINGMAX  PINGSTDEV  PINGLOSS  \\\n",
       "0             5G  -102   -10   8.0  ...       -       -          -         -   \n",
       "1             5G  -102   -10   8.0  ...       -       -          -         -   \n",
       "2             5G  -102   -10   8.0  ...       -       -          -         -   \n",
       "3             5G  -102   -10   3.0  ...       -       -          -         -   \n",
       "4             5G  -102   -10   3.0  ...       -       -          -         -   \n",
       "...          ...   ...   ...   ...  ...     ...     ...        ...       ...   \n",
       "1893          5G   -90   -11  -1.0  ...       -       -          -         -   \n",
       "1894          5G   -93   -12  -1.0  ...       -       -          -         -   \n",
       "1895          5G   -93   -12  -1.0  ...       -       -          -         -   \n",
       "1896          5G   -90   -14   1.0  ...       -       -          -         -   \n",
       "1897          5G   -90   -14   1.0  ...       -       -          -         -   \n",
       "\n",
       "     CELLHEX NODEHEX LACHEX RAWCELLID NRxRSRP NRxRSRQ  \n",
       "0          C    A81B   9CBA  11016972  -102.0    -1.0  \n",
       "1          C    A81B   9CBA  11016972  -102.0    -1.0  \n",
       "2          C    A81B   9CBA  11016972  -102.0    -1.0  \n",
       "3          C    A81B   9CBA  11016972  -101.0    -3.0  \n",
       "4          C    A81B   9CBA  11016972  -101.0    -3.0  \n",
       "...      ...     ...    ...       ...     ...     ...  \n",
       "1893       B    A9AA   9CBA  11119115   -83.0    -3.0  \n",
       "1894       B    A9AA   9CBA  11119115   -84.0    -2.0  \n",
       "1895       B    A9AA   9CBA  11119115   -84.0    -2.0  \n",
       "1896       B    A9AA   9CBA  11119115   -83.0    -2.0  \n",
       "1897       B    A9AA   9CBA  11119115   -83.0    -2.0  \n",
       "\n",
       "[1898 rows x 26 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                Timestamp  Longitude   Latitude  Speed Operatorname  CellID  \\\n",
      "0     2020.01.06_09.55.14  -8.394744  51.886172      0            B      11   \n",
      "1     2020.01.06_09.55.15  -8.394744  51.886172      0            B      11   \n",
      "2     2020.01.06_09.55.16  -8.394744  51.886172      0            B      11   \n",
      "3     2020.01.06_09.55.17  -8.394744  51.886172      0            B      11   \n",
      "4     2020.01.06_09.55.18  -8.394744  51.886172      0            B      11   \n",
      "...                   ...        ...        ...    ...          ...     ...   \n",
      "3734  2020.01.06_11.01.56  -8.394744  51.886172      0            B      11   \n",
      "3735  2020.01.06_11.01.57  -8.394744  51.886172      0            B      11   \n",
      "3736  2020.01.06_11.01.58  -8.394744  51.886172      0            B      11   \n",
      "3737  2020.01.06_11.01.59  -8.394744  51.886172      0            B      11   \n",
      "3738  2020.01.06_11.02.00  -8.394744  51.886172      0            B      11   \n",
      "\n",
      "     NetworkMode  RSRP  RSRQ  SNR  ...  PINGMIN PINGMAX  PINGSTDEV  PINGLOSS  \\\n",
      "0             5G  -103   -10  2.0  ...        -       -          -         -   \n",
      "1             5G  -102   -10  2.0  ...        -       -          -         -   \n",
      "2             5G  -102   -10  2.0  ...        -       -          -         -   \n",
      "3             5G  -102    -9 -1.0  ...        -       -          -         -   \n",
      "4             5G  -102    -9 -1.0  ...        -       -          -         -   \n",
      "...          ...   ...   ...  ...  ...      ...     ...        ...       ...   \n",
      "3734          5G  -104   -13 -5.0  ...        -       -          -         -   \n",
      "3735          5G  -104   -13 -5.0  ...        -       -          -         -   \n",
      "3736          5G  -104   -16 -3.0  ...        -       -          -         -   \n",
      "3737          5G  -104   -16 -3.0  ...        -       -          -         -   \n",
      "3738          5G  -104   -15 -2.0  ...        -       -          -         -   \n",
      "\n",
      "     CELLHEX NODEHEX LACHEX RAWCELLID NRxRSRP NRxRSRQ  \n",
      "0          B    A4DF   9CBA  10805003  -104.0   -14.0  \n",
      "1          B    A4DF   9CBA  10805003  -104.0    -8.0  \n",
      "2          B    A4DF   9CBA  10805003  -104.0    -8.0  \n",
      "3          B    A4DF   9CBA  10805003  -105.0    -8.0  \n",
      "4          B    A4DF   9CBA  10805003  -105.0    -8.0  \n",
      "...      ...     ...    ...       ...     ...     ...  \n",
      "3734       B    A4DF   9CBA  10805003       -       -  \n",
      "3735       B    A4DF   9CBA  10805003       -       -  \n",
      "3736       B    A4DF   9CBA  10805003  -105.0   -16.0  \n",
      "3737       B    A4DF   9CBA  10805003  -105.0   -16.0  \n",
      "3738       B    A4DF   9CBA  10805003  -105.0   -16.0  \n",
      "\n",
      "[3739 rows x 26 columns]\n"
     ]
    }
   ],
   "source": [
    "print(read_csv(file_static))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = read_csv(file_static)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Speed</th>\n",
       "      <th>Operatorname</th>\n",
       "      <th>CellID</th>\n",
       "      <th>NetworkMode</th>\n",
       "      <th>RSRP</th>\n",
       "      <th>RSRQ</th>\n",
       "      <th>SNR</th>\n",
       "      <th>...</th>\n",
       "      <th>PINGMIN</th>\n",
       "      <th>PINGMAX</th>\n",
       "      <th>PINGSTDEV</th>\n",
       "      <th>PINGLOSS</th>\n",
       "      <th>CELLHEX</th>\n",
       "      <th>NODEHEX</th>\n",
       "      <th>LACHEX</th>\n",
       "      <th>RAWCELLID</th>\n",
       "      <th>NRxRSRP</th>\n",
       "      <th>NRxRSRQ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020.01.06_09.55.14</td>\n",
       "      <td>-8.394744</td>\n",
       "      <td>51.886172</td>\n",
       "      <td>0</td>\n",
       "      <td>B</td>\n",
       "      <td>11</td>\n",
       "      <td>5G</td>\n",
       "      <td>-103</td>\n",
       "      <td>-10</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>B</td>\n",
       "      <td>A4DF</td>\n",
       "      <td>9CBA</td>\n",
       "      <td>10805003</td>\n",
       "      <td>-104.0</td>\n",
       "      <td>-14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020.01.06_09.55.15</td>\n",
       "      <td>-8.394744</td>\n",
       "      <td>51.886172</td>\n",
       "      <td>0</td>\n",
       "      <td>B</td>\n",
       "      <td>11</td>\n",
       "      <td>5G</td>\n",
       "      <td>-102</td>\n",
       "      <td>-10</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>B</td>\n",
       "      <td>A4DF</td>\n",
       "      <td>9CBA</td>\n",
       "      <td>10805003</td>\n",
       "      <td>-104.0</td>\n",
       "      <td>-8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020.01.06_09.55.16</td>\n",
       "      <td>-8.394744</td>\n",
       "      <td>51.886172</td>\n",
       "      <td>0</td>\n",
       "      <td>B</td>\n",
       "      <td>11</td>\n",
       "      <td>5G</td>\n",
       "      <td>-102</td>\n",
       "      <td>-10</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>B</td>\n",
       "      <td>A4DF</td>\n",
       "      <td>9CBA</td>\n",
       "      <td>10805003</td>\n",
       "      <td>-104.0</td>\n",
       "      <td>-8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020.01.06_09.55.17</td>\n",
       "      <td>-8.394744</td>\n",
       "      <td>51.886172</td>\n",
       "      <td>0</td>\n",
       "      <td>B</td>\n",
       "      <td>11</td>\n",
       "      <td>5G</td>\n",
       "      <td>-102</td>\n",
       "      <td>-9</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>B</td>\n",
       "      <td>A4DF</td>\n",
       "      <td>9CBA</td>\n",
       "      <td>10805003</td>\n",
       "      <td>-105.0</td>\n",
       "      <td>-8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020.01.06_09.55.18</td>\n",
       "      <td>-8.394744</td>\n",
       "      <td>51.886172</td>\n",
       "      <td>0</td>\n",
       "      <td>B</td>\n",
       "      <td>11</td>\n",
       "      <td>5G</td>\n",
       "      <td>-102</td>\n",
       "      <td>-9</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>B</td>\n",
       "      <td>A4DF</td>\n",
       "      <td>9CBA</td>\n",
       "      <td>10805003</td>\n",
       "      <td>-105.0</td>\n",
       "      <td>-8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3734</th>\n",
       "      <td>2020.01.06_11.01.56</td>\n",
       "      <td>-8.394744</td>\n",
       "      <td>51.886172</td>\n",
       "      <td>0</td>\n",
       "      <td>B</td>\n",
       "      <td>11</td>\n",
       "      <td>5G</td>\n",
       "      <td>-104</td>\n",
       "      <td>-13</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>B</td>\n",
       "      <td>A4DF</td>\n",
       "      <td>9CBA</td>\n",
       "      <td>10805003</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3735</th>\n",
       "      <td>2020.01.06_11.01.57</td>\n",
       "      <td>-8.394744</td>\n",
       "      <td>51.886172</td>\n",
       "      <td>0</td>\n",
       "      <td>B</td>\n",
       "      <td>11</td>\n",
       "      <td>5G</td>\n",
       "      <td>-104</td>\n",
       "      <td>-13</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>B</td>\n",
       "      <td>A4DF</td>\n",
       "      <td>9CBA</td>\n",
       "      <td>10805003</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3736</th>\n",
       "      <td>2020.01.06_11.01.58</td>\n",
       "      <td>-8.394744</td>\n",
       "      <td>51.886172</td>\n",
       "      <td>0</td>\n",
       "      <td>B</td>\n",
       "      <td>11</td>\n",
       "      <td>5G</td>\n",
       "      <td>-104</td>\n",
       "      <td>-16</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>B</td>\n",
       "      <td>A4DF</td>\n",
       "      <td>9CBA</td>\n",
       "      <td>10805003</td>\n",
       "      <td>-105.0</td>\n",
       "      <td>-16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3737</th>\n",
       "      <td>2020.01.06_11.01.59</td>\n",
       "      <td>-8.394744</td>\n",
       "      <td>51.886172</td>\n",
       "      <td>0</td>\n",
       "      <td>B</td>\n",
       "      <td>11</td>\n",
       "      <td>5G</td>\n",
       "      <td>-104</td>\n",
       "      <td>-16</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>B</td>\n",
       "      <td>A4DF</td>\n",
       "      <td>9CBA</td>\n",
       "      <td>10805003</td>\n",
       "      <td>-105.0</td>\n",
       "      <td>-16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3738</th>\n",
       "      <td>2020.01.06_11.02.00</td>\n",
       "      <td>-8.394744</td>\n",
       "      <td>51.886172</td>\n",
       "      <td>0</td>\n",
       "      <td>B</td>\n",
       "      <td>11</td>\n",
       "      <td>5G</td>\n",
       "      <td>-104</td>\n",
       "      <td>-15</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>B</td>\n",
       "      <td>A4DF</td>\n",
       "      <td>9CBA</td>\n",
       "      <td>10805003</td>\n",
       "      <td>-105.0</td>\n",
       "      <td>-16.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3739 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Timestamp  Longitude   Latitude  Speed Operatorname  CellID  \\\n",
       "0     2020.01.06_09.55.14  -8.394744  51.886172      0            B      11   \n",
       "1     2020.01.06_09.55.15  -8.394744  51.886172      0            B      11   \n",
       "2     2020.01.06_09.55.16  -8.394744  51.886172      0            B      11   \n",
       "3     2020.01.06_09.55.17  -8.394744  51.886172      0            B      11   \n",
       "4     2020.01.06_09.55.18  -8.394744  51.886172      0            B      11   \n",
       "...                   ...        ...        ...    ...          ...     ...   \n",
       "3734  2020.01.06_11.01.56  -8.394744  51.886172      0            B      11   \n",
       "3735  2020.01.06_11.01.57  -8.394744  51.886172      0            B      11   \n",
       "3736  2020.01.06_11.01.58  -8.394744  51.886172      0            B      11   \n",
       "3737  2020.01.06_11.01.59  -8.394744  51.886172      0            B      11   \n",
       "3738  2020.01.06_11.02.00  -8.394744  51.886172      0            B      11   \n",
       "\n",
       "     NetworkMode  RSRP  RSRQ  SNR  ...  PINGMIN PINGMAX  PINGSTDEV  PINGLOSS  \\\n",
       "0             5G  -103   -10  2.0  ...        -       -          -         -   \n",
       "1             5G  -102   -10  2.0  ...        -       -          -         -   \n",
       "2             5G  -102   -10  2.0  ...        -       -          -         -   \n",
       "3             5G  -102    -9 -1.0  ...        -       -          -         -   \n",
       "4             5G  -102    -9 -1.0  ...        -       -          -         -   \n",
       "...          ...   ...   ...  ...  ...      ...     ...        ...       ...   \n",
       "3734          5G  -104   -13 -5.0  ...        -       -          -         -   \n",
       "3735          5G  -104   -13 -5.0  ...        -       -          -         -   \n",
       "3736          5G  -104   -16 -3.0  ...        -       -          -         -   \n",
       "3737          5G  -104   -16 -3.0  ...        -       -          -         -   \n",
       "3738          5G  -104   -15 -2.0  ...        -       -          -         -   \n",
       "\n",
       "     CELLHEX NODEHEX LACHEX RAWCELLID NRxRSRP NRxRSRQ  \n",
       "0          B    A4DF   9CBA  10805003  -104.0   -14.0  \n",
       "1          B    A4DF   9CBA  10805003  -104.0    -8.0  \n",
       "2          B    A4DF   9CBA  10805003  -104.0    -8.0  \n",
       "3          B    A4DF   9CBA  10805003  -105.0    -8.0  \n",
       "4          B    A4DF   9CBA  10805003  -105.0    -8.0  \n",
       "...      ...     ...    ...       ...     ...     ...  \n",
       "3734       B    A4DF   9CBA  10805003       -       -  \n",
       "3735       B    A4DF   9CBA  10805003       -       -  \n",
       "3736       B    A4DF   9CBA  10805003  -105.0   -16.0  \n",
       "3737       B    A4DF   9CBA  10805003  -105.0   -16.0  \n",
       "3738       B    A4DF   9CBA  10805003  -105.0   -16.0  \n",
       "\n",
       "[3739 rows x 26 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_driver = np.array(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_static = np.array(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4.6650e-01,  4.6650e-01,  4.6650e-01,  4.6650e-01],\n",
       "       [ 2.9728e+05,  2.9728e+05,  2.9728e+05,  2.9728e+05],\n",
       "       [-1.0000e+01, -1.0000e+01, -1.0000e+01, -1.0000e+01],\n",
       "       [ 1.1719e-01,  1.1719e-01,  1.1719e-01,  1.1719e-01],\n",
       "       [ 1.0000e+00,  1.0000e+00,  1.0000e+00,  1.0000e+00]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[16728:16733]   # BER, max throughput, SNR, Code_rate, Modulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 4.6650e-01  2.9728e+05 -1.0000e+01  1.1719e-01  1.0000e+00]\n"
     ]
    }
   ],
   "source": [
    "data_ch = data[:,0]\n",
    "print(data_ch[16728:16733])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  9.858     7.1225    9.4676  ... -10.        0.11719   1.     ]\n",
      " [  1.6488    0.95614   1.6194  ...  10.        0.11719   1.     ]\n",
      " [  8.8256    8.8775    9.0031  ... -10.        0.23438   1.     ]\n",
      " ...\n",
      " [  1.6605    1.0832    1.6503  ...  18.        0.94727   1.     ]\n",
      " [  1.6574    1.0772    1.6479  ...  19.        0.94727   1.     ]\n",
      " [  1.4949    1.0295    1.5102  ...  20.        0.94727   1.     ]]\n"
     ]
    }
   ],
   "source": [
    "data_ch = np.reshape(data_ch,(-1,16733))\n",
    "print(data_ch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ch = data_ch[18:]            # SNR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-20., -19., -18., -17., -16., -15., -14., -13., -12., -11., -10.,\n",
       "        -9.,  -8.,  -7.,  -6.,  -5.,  -4.,  -3.,  -2.,  -1.,   0.,   1.,\n",
       "         2.,   3.,   4.,   5.,   6.,   7.,   8.,   9.,  10.,  11.,  12.,\n",
       "        13.,  14.,  15.,  16.,  17.,  18.,  19.,  20., -20., -19., -18.,\n",
       "       -17., -16., -15., -14., -13., -12., -11., -10.,  -9.,  -8.,  -7.,\n",
       "        -6.,  -5.,  -4.,  -3.,  -2.,  -1.,   0.,   1.,   2.,   3.,   4.,\n",
       "         5.,   6.,   7.,   8.,   9.,  10.,  11.,  12.,  13.,  14.,  15.,\n",
       "        16.,  17.,  18.,  19.,  20., -20., -19., -18., -17., -16., -15.,\n",
       "       -14., -13., -12., -11., -10.,  -9.,  -8.,  -7.,  -6.,  -5.,  -4.,\n",
       "        -3.,  -2.,  -1.,   0.,   1.,   2.,   3.,   4.,   5.,   6.,   7.,\n",
       "         8.,   9.,  10.,  11.,  12.,  13.,  14.,  15.,  16.,  17.,  18.,\n",
       "        19.,  20., -20., -19., -18., -17., -16., -15., -14., -13., -12.,\n",
       "       -11., -10.,  -9.,  -8.,  -7.,  -6.,  -5.,  -4.,  -3.,  -2.,  -1.,\n",
       "         0.,   1.,   2.,   3.,   4.,   5.,   6.,   7.,   8.,   9.,  10.,\n",
       "        11.,  12.,  13.,  14.,  15.,  16.,  17.,  18.,  19.,  20., -20.,\n",
       "       -19., -18., -17., -16., -15., -14., -13., -12., -11., -10.,  -9.,\n",
       "        -8.,  -7.,  -6.,  -5.,  -4.,  -3.,  -2.,  -1.,   0.,   1.,   2.,\n",
       "         3.,   4.,   5.,   6.,   7.,   8.,   9.,  10.,  11.,  12.,  13.,\n",
       "        14.,  15.,  16.,  17.,  18.,  19.,  20., -20., -19., -18., -17.,\n",
       "       -16., -15., -14., -13., -12., -11., -10.,  -9.,  -8.,  -7.,  -6.,\n",
       "        -5.,  -4.,  -3.,  -2.,  -1.,   0.,   1.,   2.,   3.,   4.,   5.,\n",
       "         6.,   7.,   8.,   9.,  10.,  11.,  12.,  13.,  14.,  15.,  16.,\n",
       "        17.,  18.,  19.,  20., -20., -19., -18., -17., -16., -15., -14.,\n",
       "       -13., -12., -11., -10.,  -9.,  -8.,  -7.,  -6.,  -5.,  -4.,  -3.,\n",
       "        -2.,  -1.,   0.,   1.,   2.,   3.,   4.,   5.,   6.,   7.,   8.,\n",
       "         9.,  10.,  11.,  12.,  13.,  14.,  15.,  16.,  17.,  18.,  19.,\n",
       "        20., -20., -19., -18., -17., -16., -15., -14., -13., -12., -11.,\n",
       "       -10.,  -9.,  -8.,  -7.,  -6.,  -5.,  -4.,  -3.,  -2.,  -1.,   0.,\n",
       "         1.,   2.,   3.,   4.,   5.,   6.,   7.,   8.,   9.,  10.,  11.,\n",
       "        12.,  13.,  14.,  15.,  16.,  17.,  18.,  19.,  20., -20., -19.,\n",
       "       -18., -17., -16., -15., -14., -13., -12., -11., -10.,  -9.,  -8.,\n",
       "        -7.,  -6.,  -5.,  -4.,  -3.,  -2.,  -1.,   0.,   1.,   2.,   3.,\n",
       "         4.,   5.,   6.,   7.,   8.,   9.,  10.,  11.,  12.,  13.,  14.,\n",
       "        15.,  16.,  17.,  18.,  19.,  20.])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_ch[:,16730]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(369, 16733)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_ch.shape # 41 x 9 = SNR x Code_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.11719 0.11719 0.11719 0.11719 0.11719 0.11719 0.11719 0.11719 0.11719\n",
      " 0.11719 0.11719 0.11719 0.11719 0.11719 0.11719 0.11719 0.11719 0.11719\n",
      " 0.11719 0.11719 0.11719 0.11719 0.11719 0.11719 0.11719 0.11719 0.11719\n",
      " 0.11719 0.11719 0.11719 0.11719 0.11719 0.11719 0.11719 0.11719 0.11719\n",
      " 0.11719 0.11719 0.11719 0.11719 0.11719 0.23438 0.23438 0.23438 0.23438\n",
      " 0.23438 0.23438 0.23438 0.23438 0.23438 0.23438 0.23438 0.23438 0.23438\n",
      " 0.23438 0.23438 0.23438 0.23438 0.23438 0.23438 0.23438 0.23438 0.23438\n",
      " 0.23438 0.23438 0.23438 0.23438 0.23438 0.23438 0.23438 0.23438 0.23438\n",
      " 0.23438 0.23438 0.23438 0.23438 0.23438 0.23438 0.23438 0.23438 0.23438\n",
      " 0.23438 0.38086 0.38086 0.38086 0.38086 0.38086 0.38086 0.38086 0.38086\n",
      " 0.38086 0.38086 0.38086 0.38086 0.38086 0.38086 0.38086 0.38086 0.38086\n",
      " 0.38086 0.38086 0.38086 0.38086 0.38086 0.38086 0.38086 0.38086 0.38086\n",
      " 0.38086 0.38086 0.38086 0.38086 0.38086 0.38086 0.38086 0.38086 0.38086\n",
      " 0.38086 0.38086 0.38086 0.38086 0.38086 0.38086 0.47852 0.47852 0.47852\n",
      " 0.47852 0.47852 0.47852 0.47852 0.47852 0.47852 0.47852 0.47852 0.47852\n",
      " 0.47852 0.47852 0.47852 0.47852 0.47852 0.47852 0.47852 0.47852 0.47852\n",
      " 0.47852 0.47852 0.47852 0.47852 0.47852 0.47852 0.47852 0.47852 0.47852\n",
      " 0.47852 0.47852 0.47852 0.47852 0.47852 0.47852 0.47852 0.47852 0.47852\n",
      " 0.47852 0.47852 0.58594 0.58594 0.58594 0.58594 0.58594 0.58594 0.58594\n",
      " 0.58594 0.58594 0.58594 0.58594 0.58594 0.58594 0.58594 0.58594 0.58594\n",
      " 0.58594 0.58594 0.58594 0.58594 0.58594 0.58594 0.58594 0.58594 0.58594\n",
      " 0.58594 0.58594 0.58594 0.58594 0.58594 0.58594 0.58594 0.58594 0.58594\n",
      " 0.58594 0.58594 0.58594 0.58594 0.58594 0.58594 0.58594 0.70313 0.70313\n",
      " 0.70313 0.70313 0.70313 0.70313 0.70313 0.70313 0.70313 0.70313 0.70313\n",
      " 0.70313 0.70313 0.70313 0.70313 0.70313 0.70313 0.70313 0.70313 0.70313\n",
      " 0.70313 0.70313 0.70313 0.70313 0.70313 0.70313 0.70313 0.70313 0.70313\n",
      " 0.70313 0.70313 0.70313 0.70313 0.70313 0.70313 0.70313 0.70313 0.70313\n",
      " 0.70313 0.70313 0.70313 0.75195 0.75195 0.75195 0.75195 0.75195 0.75195\n",
      " 0.75195 0.75195 0.75195 0.75195 0.75195 0.75195 0.75195 0.75195 0.75195\n",
      " 0.75195 0.75195 0.75195 0.75195 0.75195 0.75195 0.75195 0.75195 0.75195\n",
      " 0.75195 0.75195 0.75195 0.75195 0.75195 0.75195 0.75195 0.75195 0.75195\n",
      " 0.75195 0.75195 0.75195 0.75195 0.75195 0.75195 0.75195 0.75195 0.84961\n",
      " 0.84961 0.84961 0.84961 0.84961 0.84961 0.84961 0.84961 0.84961 0.84961\n",
      " 0.84961 0.84961 0.84961 0.84961 0.84961 0.84961 0.84961 0.84961 0.84961\n",
      " 0.84961 0.84961 0.84961 0.84961 0.84961 0.84961 0.84961 0.84961 0.84961\n",
      " 0.84961 0.84961 0.84961 0.84961 0.84961 0.84961 0.84961 0.84961 0.84961\n",
      " 0.84961 0.84961 0.84961 0.84961 0.94727 0.94727 0.94727 0.94727 0.94727\n",
      " 0.94727 0.94727 0.94727 0.94727 0.94727 0.94727 0.94727 0.94727 0.94727\n",
      " 0.94727 0.94727 0.94727 0.94727 0.94727 0.94727 0.94727 0.94727 0.94727\n",
      " 0.94727 0.94727 0.94727 0.94727 0.94727 0.94727 0.94727 0.94727 0.94727\n",
      " 0.94727 0.94727 0.94727 0.94727 0.94727 0.94727 0.94727 0.94727 0.94727]\n"
     ]
    }
   ],
   "source": [
    "data_cr = data_ch[:,16731].copy()\n",
    "print(data_cr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "41\n",
      "82\n",
      "123\n",
      "164\n",
      "205\n",
      "246\n",
      "287\n",
      "328\n",
      "0\n",
      "41\n",
      "82\n",
      "123\n",
      "164\n",
      "205\n",
      "246\n",
      "287\n",
      "328\n",
      "0\n",
      "41\n",
      "82\n",
      "123\n",
      "164\n",
      "205\n",
      "246\n",
      "287\n",
      "328\n",
      "0\n",
      "41\n",
      "82\n",
      "123\n",
      "164\n",
      "205\n",
      "246\n",
      "287\n",
      "328\n",
      "0\n",
      "41\n",
      "82\n",
      "123\n",
      "164\n",
      "205\n",
      "246\n",
      "287\n",
      "328\n",
      "0\n",
      "41\n",
      "82\n",
      "123\n",
      "164\n",
      "205\n",
      "246\n",
      "287\n",
      "328\n",
      "0\n",
      "41\n",
      "82\n",
      "123\n",
      "164\n",
      "205\n",
      "246\n",
      "287\n",
      "328\n",
      "0\n",
      "41\n",
      "82\n",
      "123\n",
      "164\n",
      "205\n",
      "246\n",
      "287\n",
      "328\n",
      "0\n",
      "41\n",
      "82\n",
      "123\n",
      "164\n",
      "205\n",
      "246\n",
      "287\n",
      "328\n",
      "0\n",
      "41\n",
      "82\n",
      "123\n",
      "164\n",
      "205\n",
      "246\n",
      "287\n",
      "328\n",
      "0\n",
      "41\n",
      "82\n",
      "123\n",
      "164\n",
      "205\n",
      "246\n",
      "287\n",
      "328\n",
      "0\n",
      "41\n",
      "82\n",
      "123\n",
      "164\n",
      "205\n",
      "246\n",
      "287\n",
      "328\n",
      "0\n",
      "41\n",
      "82\n",
      "123\n",
      "164\n",
      "205\n",
      "246\n",
      "287\n",
      "328\n",
      "0\n",
      "41\n",
      "82\n",
      "123\n",
      "164\n",
      "205\n",
      "246\n",
      "287\n",
      "328\n",
      "0\n",
      "41\n",
      "82\n",
      "123\n",
      "164\n",
      "205\n",
      "246\n",
      "287\n",
      "328\n",
      "0\n",
      "41\n",
      "82\n",
      "123\n",
      "164\n",
      "205\n",
      "246\n",
      "287\n",
      "328\n",
      "0\n",
      "41\n",
      "82\n",
      "123\n",
      "164\n",
      "205\n",
      "246\n",
      "287\n",
      "328\n",
      "0\n",
      "41\n",
      "82\n",
      "123\n",
      "164\n",
      "205\n",
      "246\n",
      "287\n",
      "328\n",
      "0\n",
      "41\n",
      "82\n",
      "123\n",
      "164\n",
      "205\n",
      "246\n",
      "287\n",
      "328\n",
      "0\n",
      "41\n",
      "82\n",
      "123\n",
      "164\n",
      "205\n",
      "246\n",
      "287\n",
      "328\n",
      "0\n",
      "41\n",
      "82\n",
      "123\n",
      "164\n",
      "205\n",
      "246\n",
      "287\n",
      "328\n",
      "0\n",
      "41\n",
      "82\n",
      "123\n",
      "164\n",
      "205\n",
      "246\n",
      "287\n",
      "328\n",
      "0\n",
      "41\n",
      "82\n",
      "123\n",
      "164\n",
      "205\n",
      "246\n",
      "287\n",
      "328\n",
      "0\n",
      "41\n",
      "82\n",
      "123\n",
      "164\n",
      "205\n",
      "246\n",
      "287\n",
      "328\n",
      "0\n",
      "41\n",
      "82\n",
      "123\n",
      "164\n",
      "205\n",
      "246\n",
      "287\n",
      "328\n",
      "0\n",
      "41\n",
      "82\n",
      "123\n",
      "164\n",
      "205\n",
      "246\n",
      "287\n",
      "328\n",
      "0\n",
      "41\n",
      "82\n",
      "123\n",
      "164\n",
      "205\n",
      "246\n",
      "287\n",
      "328\n",
      "0\n",
      "41\n",
      "82\n",
      "123\n",
      "164\n",
      "205\n",
      "246\n",
      "287\n",
      "328\n",
      "0\n",
      "41\n",
      "82\n",
      "123\n",
      "164\n",
      "205\n",
      "246\n",
      "287\n",
      "328\n",
      "0\n",
      "41\n",
      "82\n",
      "123\n",
      "164\n",
      "205\n",
      "246\n",
      "287\n",
      "328\n",
      "0\n",
      "41\n",
      "82\n",
      "123\n",
      "164\n",
      "205\n",
      "246\n",
      "287\n",
      "328\n",
      "0\n",
      "41\n",
      "82\n",
      "123\n",
      "164\n",
      "205\n",
      "246\n",
      "287\n",
      "328\n",
      "0\n",
      "41\n",
      "82\n",
      "123\n",
      "164\n",
      "205\n",
      "246\n",
      "287\n",
      "328\n",
      "0\n",
      "41\n",
      "82\n",
      "123\n",
      "164\n",
      "205\n",
      "246\n",
      "287\n",
      "328\n",
      "0\n",
      "41\n",
      "82\n",
      "123\n",
      "164\n",
      "205\n",
      "246\n",
      "287\n",
      "328\n",
      "0\n",
      "41\n",
      "82\n",
      "123\n",
      "164\n",
      "205\n",
      "246\n",
      "287\n",
      "328\n",
      "0\n",
      "41\n",
      "82\n",
      "123\n",
      "164\n",
      "205\n",
      "246\n",
      "287\n",
      "328\n",
      "0\n",
      "41\n",
      "82\n",
      "123\n",
      "164\n",
      "205\n",
      "246\n",
      "287\n",
      "328\n",
      "0\n",
      "41\n",
      "82\n",
      "123\n",
      "164\n",
      "205\n",
      "246\n",
      "287\n",
      "328\n",
      "0\n",
      "41\n",
      "82\n",
      "123\n",
      "164\n",
      "205\n",
      "246\n",
      "287\n",
      "328\n",
      "0\n",
      "41\n",
      "82\n",
      "123\n",
      "164\n",
      "205\n",
      "246\n",
      "287\n",
      "328\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.11719, 0.11719, 0.23438, 0.23438, 0.23438, 0.38086, 0.47852, 0.47852, 0.58594, 0.58594, 0.70313, 0.75195, 0.8496100000000001, 0.8496100000000001, 0.9472700000000001, 0.9472700000000001, 0.9472700000000001, 0.9472700000000001, 0.9472700000000001, 0.9472700000000001, 0.9472700000000001, 0.9472700000000001, 0.9472700000000001, 0.9472700000000001]\n"
     ]
    }
   ],
   "source": [
    "data_c = []\n",
    "for snr in range(41):\n",
    "    maxtr = 0\n",
    "    cr = 0\n",
    "    for i in range(0,data_ch.shape[0],41):\n",
    "        #for j in range(9):\n",
    "        if(data_ch[i+snr][16728]<0.1):\n",
    "            if(maxtr<data_ch[i+snr][16729]):\n",
    "                \n",
    "                cr = data_ch[i+snr][16731]\n",
    "                maxtr = data_ch[i+snr][16729]\n",
    "\n",
    "        print(i)\n",
    "    data_c.append(cr)\n",
    "print(data_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_new = data_ch.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 81.929    65.706    77.129   ... -20.        0.        1.     ]\n",
      " [ 57.025    50.611    54.943   ... -19.        0.        1.     ]\n",
      " [ 44.983    40.369    43.475   ... -18.        0.        1.     ]\n",
      " ...\n",
      " [  1.6605    1.0832    1.6503  ...  18.        0.94727   1.     ]\n",
      " [  1.6574    1.0772    1.6479  ...  19.        0.94727   1.     ]\n",
      " [  1.4949    1.0295    1.5102  ...  20.        0.94727   1.     ]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i in range(data_new.shape[0]):\n",
    "    data_new[i][16731] = data_c[int(data_new[i][16730]+20)]\n",
    "\n",
    "print(data_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 81.929    65.706    77.129   ... -20.        0.        1.     ]\n",
      " [ 57.025    50.611    54.943   ... -19.        0.        1.     ]\n",
      " [ 44.983    40.369    43.475   ... -18.        0.        1.     ]\n",
      " ...\n",
      " [  1.6605    1.0832    1.6503  ...  18.        0.94727   1.     ]\n",
      " [  1.6574    1.0772    1.6479  ...  19.        0.94727   1.     ]\n",
      " [  1.4949    1.0295    1.5102  ...  20.        0.94727   1.     ]]\n"
     ]
    }
   ],
   "source": [
    "data_new[:,16729] /= 1e6\n",
    "print(data_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "data_feat = data_new\n",
    "data_rescaled = scaler.fit_transform(data_feat)\n",
    "pca = IncrementalPCA(n_components=10,batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_rescaled = scaler.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.29728, 0.29728, 0.29728, 0.29728, 0.29728, 0.29728, 0.29728,\n",
       "       0.29728, 0.29728, 0.29728, 0.29728, 0.29728, 0.29728, 0.29728,\n",
       "       0.29728, 0.29728, 0.29728, 0.29728, 0.29728, 0.29728, 0.29728,\n",
       "       0.29728, 0.29728, 0.29728, 0.29728, 0.29728, 0.29728, 0.29728,\n",
       "       0.29728, 0.29728, 0.29728, 0.29728, 0.29728, 0.29728, 0.29728,\n",
       "       0.29728, 0.29728, 0.29728, 0.29728, 0.29728, 0.29728, 0.59424,\n",
       "       0.59424, 0.59424, 0.59424, 0.59424, 0.59424, 0.59424, 0.59424,\n",
       "       0.59424, 0.59424, 0.59424, 0.59424, 0.59424, 0.59424, 0.59424,\n",
       "       0.59424, 0.59424, 0.59424, 0.59424, 0.59424, 0.59424, 0.59424,\n",
       "       0.59424, 0.59424, 0.59424, 0.59424, 0.59424, 0.59424, 0.59424,\n",
       "       0.59424, 0.59424, 0.59424, 0.59424, 0.59424, 0.59424, 0.59424,\n",
       "       0.59424, 0.59424, 0.59424, 0.59424, 0.59424, 0.96288, 0.96288,\n",
       "       0.96288, 0.96288, 0.96288, 0.96288, 0.96288, 0.96288, 0.96288,\n",
       "       0.96288, 0.96288, 0.96288, 0.96288, 0.96288, 0.96288, 0.96288,\n",
       "       0.96288, 0.96288, 0.96288, 0.96288, 0.96288, 0.96288, 0.96288,\n",
       "       0.96288, 0.96288, 0.96288, 0.96288, 0.96288, 0.96288, 0.96288,\n",
       "       0.96288, 0.96288, 0.96288, 0.96288, 0.96288, 0.96288, 0.96288,\n",
       "       0.96288, 0.96288, 0.96288, 0.96288, 1.2086 , 1.2086 , 1.2086 ,\n",
       "       1.2086 , 1.2086 , 1.2086 , 1.2086 , 1.2086 , 1.2086 , 1.2086 ,\n",
       "       1.2086 , 1.2086 , 1.2086 , 1.2086 , 1.2086 , 1.2086 , 1.2086 ,\n",
       "       1.2086 , 1.2086 , 1.2086 , 1.2086 , 1.2086 , 1.2086 , 1.2086 ,\n",
       "       1.2086 , 1.2086 , 1.2086 , 1.2086 , 1.2086 , 1.2086 , 1.2086 ,\n",
       "       1.2086 , 1.2086 , 1.2086 , 1.2086 , 1.2086 , 1.2086 , 1.2086 ,\n",
       "       1.2086 , 1.2086 , 1.2086 , 1.4758 , 1.4758 , 1.4758 , 1.4758 ,\n",
       "       1.4758 , 1.4758 , 1.4758 , 1.4758 , 1.4758 , 1.4758 , 1.4758 ,\n",
       "       1.4758 , 1.4758 , 1.4758 , 1.4758 , 1.4758 , 1.4758 , 1.4758 ,\n",
       "       1.4758 , 1.4758 , 1.4758 , 1.4758 , 1.4758 , 1.4758 , 1.4758 ,\n",
       "       1.4758 , 1.4758 , 1.4758 , 1.4758 , 1.4758 , 1.4758 , 1.4758 ,\n",
       "       1.4758 , 1.4758 , 1.4758 , 1.4758 , 1.4758 , 1.4758 , 1.4758 ,\n",
       "       1.4758 , 1.4758 , 1.8038 , 1.8038 , 1.8038 , 1.8038 , 1.8038 ,\n",
       "       1.8038 , 1.8038 , 1.8038 , 1.8038 , 1.8038 , 1.8038 , 1.8038 ,\n",
       "       1.8038 , 1.8038 , 1.8038 , 1.8038 , 1.8038 , 1.8038 , 1.8038 ,\n",
       "       1.8038 , 1.8038 , 1.8038 , 1.8038 , 1.8038 , 1.8038 , 1.8038 ,\n",
       "       1.8038 , 1.8038 , 1.8038 , 1.8038 , 1.8038 , 1.8038 , 1.8038 ,\n",
       "       1.8038 , 1.8038 , 1.8038 , 1.8038 , 1.8038 , 1.8038 , 1.8038 ,\n",
       "       1.8038 , 1.9267 , 1.9267 , 1.9267 , 1.9267 , 1.9267 , 1.9267 ,\n",
       "       1.9267 , 1.9267 , 1.9267 , 1.9267 , 1.9267 , 1.9267 , 1.9267 ,\n",
       "       1.9267 , 1.9267 , 1.9267 , 1.9267 , 1.9267 , 1.9267 , 1.9267 ,\n",
       "       1.9267 , 1.9267 , 1.9267 , 1.9267 , 1.9267 , 1.9267 , 1.9267 ,\n",
       "       1.9267 , 1.9267 , 1.9267 , 1.9267 , 1.9267 , 1.9267 , 1.9267 ,\n",
       "       1.9267 , 1.9267 , 1.9267 , 1.9267 , 1.9267 , 1.9267 , 1.9267 ,\n",
       "       2.1718 , 2.1718 , 2.1718 , 2.1718 , 2.1718 , 2.1718 , 2.1718 ,\n",
       "       2.1718 , 2.1718 , 2.1718 , 2.1718 , 2.1718 , 2.1718 , 2.1718 ,\n",
       "       2.1718 , 2.1718 , 2.1718 , 2.1718 , 2.1718 , 2.1718 , 2.1718 ,\n",
       "       2.1718 , 2.1718 , 2.1718 , 2.1718 , 2.1718 , 2.1718 , 2.1718 ,\n",
       "       2.1718 , 2.1718 , 2.1718 , 2.1718 , 2.1718 , 2.1718 , 2.1718 ,\n",
       "       2.1718 , 2.1718 , 2.1718 , 2.1718 , 2.1718 , 2.1718 , 2.4182 ,\n",
       "       2.4182 , 2.4182 , 2.4182 , 2.4182 , 2.4182 , 2.4182 , 2.4182 ,\n",
       "       2.4182 , 2.4182 , 2.4182 , 2.4182 , 2.4182 , 2.4182 , 2.4182 ,\n",
       "       2.4182 , 2.4182 , 2.4182 , 2.4182 , 2.4182 , 2.4182 , 2.4182 ,\n",
       "       2.4182 , 2.4182 , 2.4182 , 2.4182 , 2.4182 , 2.4182 , 2.4182 ,\n",
       "       2.4182 , 2.4182 , 2.4182 , 2.4182 , 2.4182 , 2.4182 , 2.4182 ,\n",
       "       2.4182 , 2.4182 , 2.4182 , 2.4182 , 2.4182 ])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_feat[:,16729]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svd = TruncatedSVD(n_components=50, n_iter=20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svd.fit(data_rescaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(svd.explained_variance_ratio_)\n",
    "print(svd.explained_variance_ratio_.sum())\n",
    "print(svd.singular_values_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = IncrementalPCA(n_components=15,batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IncrementalPCA(batch_size=100, copy=True, n_components=15, whiten=False)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.fit(data_rescaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9.92504066e-01 1.17778328e-03 9.80622942e-04 7.89355524e-04\n",
      " 6.64665047e-04 5.99407844e-04 5.69621232e-04 4.76213300e-04\n",
      " 4.34785481e-04 4.31517379e-04 1.98559154e-04 1.48224952e-04\n",
      " 1.30294851e-04 1.20908677e-04 9.55421662e-05]\n",
      "0.9993215677460666\n",
      "[477.78610138  16.45887157  15.0182175   13.47422178  12.36427869\n",
      "  11.741635    11.44617679  10.46569623  10.0001124    9.96245816\n",
      "   6.75790872   5.83885948   5.47433023   5.27346538   4.68775501]\n"
     ]
    }
   ],
   "source": [
    "print(pca.explained_variance_ratio_)\n",
    "print(pca.explained_variance_ratio_.sum())\n",
    "print(pca.singular_values_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_trans = pca.transform(data_rescaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_trans = pca.transform(test_rescaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 100)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_trans.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(369, 16731)\n"
     ]
    }
   ],
   "source": [
    "X_train = data_rescaled[:,:16731]\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(369, 2)\n"
     ]
    }
   ],
   "source": [
    "y_train = data_rescaled[:,16731:]\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = IncrementalPCA(n_components=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shubham/anaconda3/lib/python3.7/site-packages/sklearn/decomposition/_incremental_pca.py:297: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio = S ** 2 / np.sum(col_var * n_total_samples)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "IncrementalPCA(batch_size=None, copy=True, n_components=1, whiten=False)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.fit(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.]\n",
      "1.0000000000000004\n",
      "[8.17097746]\n"
     ]
    }
   ],
   "source": [
    "print(pca.explained_variance_ratio_)\n",
    "print(pca.explained_variance_ratio_.sum())\n",
    "print(pca.singular_values_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.53463923]\n",
      " [-0.53463923]\n",
      " [-0.39346007]\n",
      " [-0.39346007]\n",
      " [-0.21699515]\n",
      " [-0.21699515]\n",
      " [-0.09934384]\n",
      " [-0.09934384]\n",
      " [ 0.03006538]\n",
      " [ 0.03006538]\n",
      " [ 0.17124454]\n",
      " [ 0.17124454]\n",
      " [ 0.23005815]\n",
      " [ 0.23005815]\n",
      " [ 0.34770946]\n",
      " [ 0.34770946]\n",
      " [ 0.46536077]\n",
      " [ 0.46536077]\n",
      " [-0.53463923]\n",
      " [-0.53463923]\n",
      " [-0.53463923]\n",
      " [-0.53463923]\n",
      " [-0.53463923]\n",
      " [-0.53463923]\n",
      " [-0.53463923]\n",
      " [-0.53463923]\n",
      " [-0.53463923]\n",
      " [-0.53463923]\n",
      " [-0.53463923]\n",
      " [-0.53463923]\n",
      " [-0.53463923]\n",
      " [-0.53463923]\n",
      " [-0.53463923]\n",
      " [-0.53463923]\n",
      " [-0.53463923]\n",
      " [-0.53463923]\n",
      " [-0.53463923]\n",
      " [-0.53463923]\n",
      " [-0.53463923]\n",
      " [-0.53463923]\n",
      " [-0.53463923]\n",
      " [-0.53463923]\n",
      " [-0.53463923]\n",
      " [-0.53463923]\n",
      " [-0.53463923]\n",
      " [-0.53463923]\n",
      " [-0.53463923]\n",
      " [-0.53463923]\n",
      " [-0.53463923]\n",
      " [-0.53463923]\n",
      " [-0.53463923]\n",
      " [-0.53463923]\n",
      " [-0.53463923]\n",
      " [-0.53463923]\n",
      " [-0.53463923]\n",
      " [-0.53463923]\n",
      " [-0.53463923]\n",
      " [-0.53463923]\n",
      " [-0.53463923]\n",
      " [-0.39346007]\n",
      " [-0.39346007]\n",
      " [-0.39346007]\n",
      " [-0.39346007]\n",
      " [-0.39346007]\n",
      " [-0.39346007]\n",
      " [-0.39346007]\n",
      " [-0.39346007]\n",
      " [-0.39346007]\n",
      " [-0.39346007]\n",
      " [-0.39346007]\n",
      " [-0.39346007]\n",
      " [-0.39346007]\n",
      " [-0.39346007]\n",
      " [-0.39346007]\n",
      " [-0.39346007]\n",
      " [-0.39346007]\n",
      " [-0.39346007]\n",
      " [-0.39346007]\n",
      " [-0.39346007]\n",
      " [-0.39346007]\n",
      " [-0.39346007]\n",
      " [-0.39346007]\n",
      " [-0.39346007]\n",
      " [-0.39346007]\n",
      " [-0.39346007]\n",
      " [-0.39346007]\n",
      " [-0.39346007]\n",
      " [-0.39346007]\n",
      " [-0.39346007]\n",
      " [-0.39346007]\n",
      " [-0.39346007]\n",
      " [-0.39346007]\n",
      " [-0.39346007]\n",
      " [-0.39346007]\n",
      " [-0.39346007]\n",
      " [-0.39346007]\n",
      " [-0.39346007]\n",
      " [-0.39346007]\n",
      " [-0.39346007]\n",
      " [-0.39346007]\n",
      " [-0.21699515]\n",
      " [-0.21699515]\n",
      " [-0.21699515]\n",
      " [-0.21699515]\n",
      " [-0.21699515]\n",
      " [-0.21699515]\n",
      " [-0.21699515]\n",
      " [-0.21699515]\n",
      " [-0.21699515]\n",
      " [-0.21699515]\n",
      " [-0.21699515]\n",
      " [-0.21699515]\n",
      " [-0.21699515]\n",
      " [-0.21699515]\n",
      " [-0.21699515]\n",
      " [-0.21699515]\n",
      " [-0.21699515]\n",
      " [-0.21699515]\n",
      " [-0.21699515]\n",
      " [-0.21699515]\n",
      " [-0.21699515]\n",
      " [-0.21699515]\n",
      " [-0.21699515]\n",
      " [-0.21699515]\n",
      " [-0.21699515]\n",
      " [-0.21699515]\n",
      " [-0.21699515]\n",
      " [-0.21699515]\n",
      " [-0.21699515]\n",
      " [-0.21699515]\n",
      " [-0.21699515]\n",
      " [-0.21699515]\n",
      " [-0.21699515]\n",
      " [-0.21699515]\n",
      " [-0.21699515]\n",
      " [-0.21699515]\n",
      " [-0.21699515]\n",
      " [-0.21699515]\n",
      " [-0.21699515]\n",
      " [-0.21699515]\n",
      " [-0.21699515]\n",
      " [-0.09934384]\n",
      " [-0.09934384]\n",
      " [-0.09934384]\n",
      " [-0.09934384]\n",
      " [-0.09934384]\n",
      " [-0.09934384]\n",
      " [-0.09934384]\n",
      " [-0.09934384]\n",
      " [-0.09934384]\n",
      " [-0.09934384]\n",
      " [-0.09934384]\n",
      " [-0.09934384]\n",
      " [-0.09934384]\n",
      " [-0.09934384]\n",
      " [-0.09934384]\n",
      " [-0.09934384]\n",
      " [-0.09934384]\n",
      " [-0.09934384]\n",
      " [-0.09934384]\n",
      " [-0.09934384]\n",
      " [-0.09934384]\n",
      " [-0.09934384]\n",
      " [-0.09934384]\n",
      " [-0.09934384]\n",
      " [-0.09934384]\n",
      " [-0.09934384]\n",
      " [-0.09934384]\n",
      " [-0.09934384]\n",
      " [-0.09934384]\n",
      " [-0.09934384]\n",
      " [-0.09934384]\n",
      " [-0.09934384]\n",
      " [-0.09934384]\n",
      " [-0.09934384]\n",
      " [-0.09934384]\n",
      " [-0.09934384]\n",
      " [-0.09934384]\n",
      " [-0.09934384]\n",
      " [-0.09934384]\n",
      " [-0.09934384]\n",
      " [-0.09934384]\n",
      " [ 0.03006538]\n",
      " [ 0.03006538]\n",
      " [ 0.03006538]\n",
      " [ 0.03006538]\n",
      " [ 0.03006538]\n",
      " [ 0.03006538]\n",
      " [ 0.03006538]\n",
      " [ 0.03006538]\n",
      " [ 0.03006538]\n",
      " [ 0.03006538]\n",
      " [ 0.03006538]\n",
      " [ 0.03006538]\n",
      " [ 0.03006538]\n",
      " [ 0.03006538]\n",
      " [ 0.03006538]\n",
      " [ 0.03006538]\n",
      " [ 0.03006538]\n",
      " [ 0.03006538]\n",
      " [ 0.03006538]\n",
      " [ 0.03006538]\n",
      " [ 0.03006538]\n",
      " [ 0.03006538]\n",
      " [ 0.03006538]\n",
      " [ 0.03006538]\n",
      " [ 0.03006538]\n",
      " [ 0.03006538]\n",
      " [ 0.03006538]\n",
      " [ 0.03006538]\n",
      " [ 0.03006538]\n",
      " [ 0.03006538]\n",
      " [ 0.03006538]\n",
      " [ 0.03006538]\n",
      " [ 0.03006538]\n",
      " [ 0.03006538]\n",
      " [ 0.03006538]\n",
      " [ 0.03006538]\n",
      " [ 0.03006538]\n",
      " [ 0.03006538]\n",
      " [ 0.03006538]\n",
      " [ 0.03006538]\n",
      " [ 0.03006538]\n",
      " [ 0.17124454]\n",
      " [ 0.17124454]\n",
      " [ 0.17124454]\n",
      " [ 0.17124454]\n",
      " [ 0.17124454]\n",
      " [ 0.17124454]\n",
      " [ 0.17124454]\n",
      " [ 0.17124454]\n",
      " [ 0.17124454]\n",
      " [ 0.17124454]\n",
      " [ 0.17124454]\n",
      " [ 0.17124454]\n",
      " [ 0.17124454]\n",
      " [ 0.17124454]\n",
      " [ 0.17124454]\n",
      " [ 0.17124454]\n",
      " [ 0.17124454]\n",
      " [ 0.17124454]\n",
      " [ 0.17124454]\n",
      " [ 0.17124454]\n",
      " [ 0.17124454]\n",
      " [ 0.17124454]\n",
      " [ 0.17124454]\n",
      " [ 0.17124454]\n",
      " [ 0.17124454]\n",
      " [ 0.17124454]\n",
      " [ 0.17124454]\n",
      " [ 0.17124454]\n",
      " [ 0.17124454]\n",
      " [ 0.17124454]\n",
      " [ 0.17124454]\n",
      " [ 0.17124454]\n",
      " [ 0.17124454]\n",
      " [ 0.17124454]\n",
      " [ 0.17124454]\n",
      " [ 0.17124454]\n",
      " [ 0.17124454]\n",
      " [ 0.17124454]\n",
      " [ 0.17124454]\n",
      " [ 0.17124454]\n",
      " [ 0.17124454]\n",
      " [ 0.23005815]\n",
      " [ 0.23005815]\n",
      " [ 0.23005815]\n",
      " [ 0.23005815]\n",
      " [ 0.23005815]\n",
      " [ 0.23005815]\n",
      " [ 0.23005815]\n",
      " [ 0.23005815]\n",
      " [ 0.23005815]\n",
      " [ 0.23005815]\n",
      " [ 0.23005815]\n",
      " [ 0.23005815]\n",
      " [ 0.23005815]\n",
      " [ 0.23005815]\n",
      " [ 0.23005815]\n",
      " [ 0.23005815]\n",
      " [ 0.23005815]\n",
      " [ 0.23005815]\n",
      " [ 0.23005815]\n",
      " [ 0.23005815]\n",
      " [ 0.23005815]\n",
      " [ 0.23005815]\n",
      " [ 0.23005815]\n",
      " [ 0.23005815]\n",
      " [ 0.23005815]\n",
      " [ 0.23005815]\n",
      " [ 0.23005815]\n",
      " [ 0.23005815]\n",
      " [ 0.23005815]\n",
      " [ 0.23005815]\n",
      " [ 0.23005815]\n",
      " [ 0.23005815]\n",
      " [ 0.23005815]\n",
      " [ 0.23005815]\n",
      " [ 0.23005815]\n",
      " [ 0.23005815]\n",
      " [ 0.23005815]\n",
      " [ 0.23005815]\n",
      " [ 0.23005815]\n",
      " [ 0.23005815]\n",
      " [ 0.23005815]\n",
      " [ 0.34770946]\n",
      " [ 0.34770946]\n",
      " [ 0.34770946]\n",
      " [ 0.34770946]\n",
      " [ 0.34770946]\n",
      " [ 0.34770946]\n",
      " [ 0.34770946]\n",
      " [ 0.34770946]\n",
      " [ 0.34770946]\n",
      " [ 0.34770946]\n",
      " [ 0.34770946]\n",
      " [ 0.34770946]\n",
      " [ 0.34770946]\n",
      " [ 0.34770946]\n",
      " [ 0.34770946]\n",
      " [ 0.34770946]\n",
      " [ 0.34770946]\n",
      " [ 0.34770946]\n",
      " [ 0.34770946]\n",
      " [ 0.34770946]\n",
      " [ 0.34770946]\n",
      " [ 0.34770946]\n",
      " [ 0.34770946]\n",
      " [ 0.34770946]\n",
      " [ 0.34770946]\n",
      " [ 0.34770946]\n",
      " [ 0.34770946]\n",
      " [ 0.34770946]\n",
      " [ 0.34770946]\n",
      " [ 0.34770946]\n",
      " [ 0.34770946]\n",
      " [ 0.34770946]\n",
      " [ 0.34770946]\n",
      " [ 0.34770946]\n",
      " [ 0.34770946]\n",
      " [ 0.34770946]\n",
      " [ 0.34770946]\n",
      " [ 0.34770946]\n",
      " [ 0.34770946]\n",
      " [ 0.34770946]\n",
      " [ 0.34770946]\n",
      " [ 0.46536077]\n",
      " [ 0.46536077]\n",
      " [ 0.46536077]\n",
      " [ 0.46536077]\n",
      " [ 0.46536077]\n",
      " [ 0.46536077]\n",
      " [ 0.46536077]\n",
      " [ 0.46536077]\n",
      " [ 0.46536077]\n",
      " [ 0.46536077]\n",
      " [ 0.46536077]\n",
      " [ 0.46536077]\n",
      " [ 0.46536077]\n",
      " [ 0.46536077]\n",
      " [ 0.46536077]\n",
      " [ 0.46536077]\n",
      " [ 0.46536077]\n",
      " [ 0.46536077]\n",
      " [ 0.46536077]\n",
      " [ 0.46536077]\n",
      " [ 0.46536077]\n",
      " [ 0.46536077]\n",
      " [ 0.46536077]\n",
      " [ 0.46536077]\n",
      " [ 0.46536077]\n",
      " [ 0.46536077]\n",
      " [ 0.46536077]\n",
      " [ 0.46536077]\n",
      " [ 0.46536077]\n",
      " [ 0.46536077]\n",
      " [ 0.46536077]\n",
      " [ 0.46536077]\n",
      " [ 0.46536077]\n",
      " [ 0.46536077]\n",
      " [ 0.46536077]\n",
      " [ 0.46536077]\n",
      " [ 0.46536077]\n",
      " [ 0.46536077]\n",
      " [ 0.46536077]\n",
      " [ 0.46536077]\n",
      " [ 0.46536077]]\n"
     ]
    }
   ],
   "source": [
    "y_train = pca.transform(y_train)\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-5.]\n",
      " [-5.]\n",
      " [-4.]\n",
      " [-4.]\n",
      " [-2.]\n",
      " [-2.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 2.]\n",
      " [ 2.]\n",
      " [ 2.]\n",
      " [ 2.]\n",
      " [ 3.]\n",
      " [ 3.]\n",
      " [ 5.]\n",
      " [ 5.]\n",
      " [-5.]\n",
      " [-5.]\n",
      " [-5.]\n",
      " [-5.]\n",
      " [-5.]\n",
      " [-5.]\n",
      " [-5.]\n",
      " [-5.]\n",
      " [-5.]\n",
      " [-5.]\n",
      " [-5.]\n",
      " [-5.]\n",
      " [-5.]\n",
      " [-5.]\n",
      " [-5.]\n",
      " [-5.]\n",
      " [-5.]\n",
      " [-5.]\n",
      " [-5.]\n",
      " [-5.]\n",
      " [-5.]\n",
      " [-5.]\n",
      " [-5.]\n",
      " [-5.]\n",
      " [-5.]\n",
      " [-5.]\n",
      " [-5.]\n",
      " [-5.]\n",
      " [-5.]\n",
      " [-5.]\n",
      " [-5.]\n",
      " [-5.]\n",
      " [-5.]\n",
      " [-5.]\n",
      " [-5.]\n",
      " [-5.]\n",
      " [-5.]\n",
      " [-5.]\n",
      " [-5.]\n",
      " [-5.]\n",
      " [-5.]\n",
      " [-4.]\n",
      " [-4.]\n",
      " [-4.]\n",
      " [-4.]\n",
      " [-4.]\n",
      " [-4.]\n",
      " [-4.]\n",
      " [-4.]\n",
      " [-4.]\n",
      " [-4.]\n",
      " [-4.]\n",
      " [-4.]\n",
      " [-4.]\n",
      " [-4.]\n",
      " [-4.]\n",
      " [-4.]\n",
      " [-4.]\n",
      " [-4.]\n",
      " [-4.]\n",
      " [-4.]\n",
      " [-4.]\n",
      " [-4.]\n",
      " [-4.]\n",
      " [-4.]\n",
      " [-4.]\n",
      " [-4.]\n",
      " [-4.]\n",
      " [-4.]\n",
      " [-4.]\n",
      " [-4.]\n",
      " [-4.]\n",
      " [-4.]\n",
      " [-4.]\n",
      " [-4.]\n",
      " [-4.]\n",
      " [-4.]\n",
      " [-4.]\n",
      " [-4.]\n",
      " [-4.]\n",
      " [-4.]\n",
      " [-4.]\n",
      " [-2.]\n",
      " [-2.]\n",
      " [-2.]\n",
      " [-2.]\n",
      " [-2.]\n",
      " [-2.]\n",
      " [-2.]\n",
      " [-2.]\n",
      " [-2.]\n",
      " [-2.]\n",
      " [-2.]\n",
      " [-2.]\n",
      " [-2.]\n",
      " [-2.]\n",
      " [-2.]\n",
      " [-2.]\n",
      " [-2.]\n",
      " [-2.]\n",
      " [-2.]\n",
      " [-2.]\n",
      " [-2.]\n",
      " [-2.]\n",
      " [-2.]\n",
      " [-2.]\n",
      " [-2.]\n",
      " [-2.]\n",
      " [-2.]\n",
      " [-2.]\n",
      " [-2.]\n",
      " [-2.]\n",
      " [-2.]\n",
      " [-2.]\n",
      " [-2.]\n",
      " [-2.]\n",
      " [-2.]\n",
      " [-2.]\n",
      " [-2.]\n",
      " [-2.]\n",
      " [-2.]\n",
      " [-2.]\n",
      " [-2.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 2.]\n",
      " [ 2.]\n",
      " [ 2.]\n",
      " [ 2.]\n",
      " [ 2.]\n",
      " [ 2.]\n",
      " [ 2.]\n",
      " [ 2.]\n",
      " [ 2.]\n",
      " [ 2.]\n",
      " [ 2.]\n",
      " [ 2.]\n",
      " [ 2.]\n",
      " [ 2.]\n",
      " [ 2.]\n",
      " [ 2.]\n",
      " [ 2.]\n",
      " [ 2.]\n",
      " [ 2.]\n",
      " [ 2.]\n",
      " [ 2.]\n",
      " [ 2.]\n",
      " [ 2.]\n",
      " [ 2.]\n",
      " [ 2.]\n",
      " [ 2.]\n",
      " [ 2.]\n",
      " [ 2.]\n",
      " [ 2.]\n",
      " [ 2.]\n",
      " [ 2.]\n",
      " [ 2.]\n",
      " [ 2.]\n",
      " [ 2.]\n",
      " [ 2.]\n",
      " [ 2.]\n",
      " [ 2.]\n",
      " [ 2.]\n",
      " [ 2.]\n",
      " [ 2.]\n",
      " [ 2.]\n",
      " [ 2.]\n",
      " [ 2.]\n",
      " [ 2.]\n",
      " [ 2.]\n",
      " [ 2.]\n",
      " [ 2.]\n",
      " [ 2.]\n",
      " [ 2.]\n",
      " [ 2.]\n",
      " [ 2.]\n",
      " [ 2.]\n",
      " [ 2.]\n",
      " [ 2.]\n",
      " [ 2.]\n",
      " [ 2.]\n",
      " [ 2.]\n",
      " [ 2.]\n",
      " [ 2.]\n",
      " [ 2.]\n",
      " [ 2.]\n",
      " [ 2.]\n",
      " [ 2.]\n",
      " [ 2.]\n",
      " [ 2.]\n",
      " [ 2.]\n",
      " [ 2.]\n",
      " [ 2.]\n",
      " [ 2.]\n",
      " [ 2.]\n",
      " [ 2.]\n",
      " [ 2.]\n",
      " [ 2.]\n",
      " [ 2.]\n",
      " [ 2.]\n",
      " [ 2.]\n",
      " [ 2.]\n",
      " [ 2.]\n",
      " [ 2.]\n",
      " [ 2.]\n",
      " [ 2.]\n",
      " [ 2.]\n",
      " [ 3.]\n",
      " [ 3.]\n",
      " [ 3.]\n",
      " [ 3.]\n",
      " [ 3.]\n",
      " [ 3.]\n",
      " [ 3.]\n",
      " [ 3.]\n",
      " [ 3.]\n",
      " [ 3.]\n",
      " [ 3.]\n",
      " [ 3.]\n",
      " [ 3.]\n",
      " [ 3.]\n",
      " [ 3.]\n",
      " [ 3.]\n",
      " [ 3.]\n",
      " [ 3.]\n",
      " [ 3.]\n",
      " [ 3.]\n",
      " [ 3.]\n",
      " [ 3.]\n",
      " [ 3.]\n",
      " [ 3.]\n",
      " [ 3.]\n",
      " [ 3.]\n",
      " [ 3.]\n",
      " [ 3.]\n",
      " [ 3.]\n",
      " [ 3.]\n",
      " [ 3.]\n",
      " [ 3.]\n",
      " [ 3.]\n",
      " [ 3.]\n",
      " [ 3.]\n",
      " [ 3.]\n",
      " [ 3.]\n",
      " [ 3.]\n",
      " [ 3.]\n",
      " [ 3.]\n",
      " [ 3.]\n",
      " [ 5.]\n",
      " [ 5.]\n",
      " [ 5.]\n",
      " [ 5.]\n",
      " [ 5.]\n",
      " [ 5.]\n",
      " [ 5.]\n",
      " [ 5.]\n",
      " [ 5.]\n",
      " [ 5.]\n",
      " [ 5.]\n",
      " [ 5.]\n",
      " [ 5.]\n",
      " [ 5.]\n",
      " [ 5.]\n",
      " [ 5.]\n",
      " [ 5.]\n",
      " [ 5.]\n",
      " [ 5.]\n",
      " [ 5.]\n",
      " [ 5.]\n",
      " [ 5.]\n",
      " [ 5.]\n",
      " [ 5.]\n",
      " [ 5.]\n",
      " [ 5.]\n",
      " [ 5.]\n",
      " [ 5.]\n",
      " [ 5.]\n",
      " [ 5.]\n",
      " [ 5.]\n",
      " [ 5.]\n",
      " [ 5.]\n",
      " [ 5.]\n",
      " [ 5.]\n",
      " [ 5.]\n",
      " [ 5.]\n",
      " [ 5.]\n",
      " [ 5.]\n",
      " [ 5.]\n",
      " [ 5.]]\n"
     ]
    }
   ],
   "source": [
    "y_train = np.round(10*y_train)\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 3.]\n",
      " [ 3.]\n",
      " [ 4.]\n",
      " [ 4.]\n",
      " [ 5.]\n",
      " [ 5.]\n",
      " [ 7.]\n",
      " [ 7.]\n",
      " [ 7.]\n",
      " [ 7.]\n",
      " [ 8.]\n",
      " [ 8.]\n",
      " [10.]\n",
      " [10.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 3.]\n",
      " [ 3.]\n",
      " [ 3.]\n",
      " [ 3.]\n",
      " [ 3.]\n",
      " [ 3.]\n",
      " [ 3.]\n",
      " [ 3.]\n",
      " [ 3.]\n",
      " [ 3.]\n",
      " [ 3.]\n",
      " [ 3.]\n",
      " [ 3.]\n",
      " [ 3.]\n",
      " [ 3.]\n",
      " [ 3.]\n",
      " [ 3.]\n",
      " [ 3.]\n",
      " [ 3.]\n",
      " [ 3.]\n",
      " [ 3.]\n",
      " [ 3.]\n",
      " [ 3.]\n",
      " [ 3.]\n",
      " [ 3.]\n",
      " [ 3.]\n",
      " [ 3.]\n",
      " [ 3.]\n",
      " [ 3.]\n",
      " [ 3.]\n",
      " [ 3.]\n",
      " [ 3.]\n",
      " [ 3.]\n",
      " [ 3.]\n",
      " [ 3.]\n",
      " [ 3.]\n",
      " [ 3.]\n",
      " [ 3.]\n",
      " [ 3.]\n",
      " [ 3.]\n",
      " [ 3.]\n",
      " [ 4.]\n",
      " [ 4.]\n",
      " [ 4.]\n",
      " [ 4.]\n",
      " [ 4.]\n",
      " [ 4.]\n",
      " [ 4.]\n",
      " [ 4.]\n",
      " [ 4.]\n",
      " [ 4.]\n",
      " [ 4.]\n",
      " [ 4.]\n",
      " [ 4.]\n",
      " [ 4.]\n",
      " [ 4.]\n",
      " [ 4.]\n",
      " [ 4.]\n",
      " [ 4.]\n",
      " [ 4.]\n",
      " [ 4.]\n",
      " [ 4.]\n",
      " [ 4.]\n",
      " [ 4.]\n",
      " [ 4.]\n",
      " [ 4.]\n",
      " [ 4.]\n",
      " [ 4.]\n",
      " [ 4.]\n",
      " [ 4.]\n",
      " [ 4.]\n",
      " [ 4.]\n",
      " [ 4.]\n",
      " [ 4.]\n",
      " [ 4.]\n",
      " [ 4.]\n",
      " [ 4.]\n",
      " [ 4.]\n",
      " [ 4.]\n",
      " [ 4.]\n",
      " [ 4.]\n",
      " [ 4.]\n",
      " [ 5.]\n",
      " [ 5.]\n",
      " [ 5.]\n",
      " [ 5.]\n",
      " [ 5.]\n",
      " [ 5.]\n",
      " [ 5.]\n",
      " [ 5.]\n",
      " [ 5.]\n",
      " [ 5.]\n",
      " [ 5.]\n",
      " [ 5.]\n",
      " [ 5.]\n",
      " [ 5.]\n",
      " [ 5.]\n",
      " [ 5.]\n",
      " [ 5.]\n",
      " [ 5.]\n",
      " [ 5.]\n",
      " [ 5.]\n",
      " [ 5.]\n",
      " [ 5.]\n",
      " [ 5.]\n",
      " [ 5.]\n",
      " [ 5.]\n",
      " [ 5.]\n",
      " [ 5.]\n",
      " [ 5.]\n",
      " [ 5.]\n",
      " [ 5.]\n",
      " [ 5.]\n",
      " [ 5.]\n",
      " [ 5.]\n",
      " [ 5.]\n",
      " [ 5.]\n",
      " [ 5.]\n",
      " [ 5.]\n",
      " [ 5.]\n",
      " [ 5.]\n",
      " [ 5.]\n",
      " [ 5.]\n",
      " [ 7.]\n",
      " [ 7.]\n",
      " [ 7.]\n",
      " [ 7.]\n",
      " [ 7.]\n",
      " [ 7.]\n",
      " [ 7.]\n",
      " [ 7.]\n",
      " [ 7.]\n",
      " [ 7.]\n",
      " [ 7.]\n",
      " [ 7.]\n",
      " [ 7.]\n",
      " [ 7.]\n",
      " [ 7.]\n",
      " [ 7.]\n",
      " [ 7.]\n",
      " [ 7.]\n",
      " [ 7.]\n",
      " [ 7.]\n",
      " [ 7.]\n",
      " [ 7.]\n",
      " [ 7.]\n",
      " [ 7.]\n",
      " [ 7.]\n",
      " [ 7.]\n",
      " [ 7.]\n",
      " [ 7.]\n",
      " [ 7.]\n",
      " [ 7.]\n",
      " [ 7.]\n",
      " [ 7.]\n",
      " [ 7.]\n",
      " [ 7.]\n",
      " [ 7.]\n",
      " [ 7.]\n",
      " [ 7.]\n",
      " [ 7.]\n",
      " [ 7.]\n",
      " [ 7.]\n",
      " [ 7.]\n",
      " [ 7.]\n",
      " [ 7.]\n",
      " [ 7.]\n",
      " [ 7.]\n",
      " [ 7.]\n",
      " [ 7.]\n",
      " [ 7.]\n",
      " [ 7.]\n",
      " [ 7.]\n",
      " [ 7.]\n",
      " [ 7.]\n",
      " [ 7.]\n",
      " [ 7.]\n",
      " [ 7.]\n",
      " [ 7.]\n",
      " [ 7.]\n",
      " [ 7.]\n",
      " [ 7.]\n",
      " [ 7.]\n",
      " [ 7.]\n",
      " [ 7.]\n",
      " [ 7.]\n",
      " [ 7.]\n",
      " [ 7.]\n",
      " [ 7.]\n",
      " [ 7.]\n",
      " [ 7.]\n",
      " [ 7.]\n",
      " [ 7.]\n",
      " [ 7.]\n",
      " [ 7.]\n",
      " [ 7.]\n",
      " [ 7.]\n",
      " [ 7.]\n",
      " [ 7.]\n",
      " [ 7.]\n",
      " [ 7.]\n",
      " [ 7.]\n",
      " [ 7.]\n",
      " [ 7.]\n",
      " [ 7.]\n",
      " [ 8.]\n",
      " [ 8.]\n",
      " [ 8.]\n",
      " [ 8.]\n",
      " [ 8.]\n",
      " [ 8.]\n",
      " [ 8.]\n",
      " [ 8.]\n",
      " [ 8.]\n",
      " [ 8.]\n",
      " [ 8.]\n",
      " [ 8.]\n",
      " [ 8.]\n",
      " [ 8.]\n",
      " [ 8.]\n",
      " [ 8.]\n",
      " [ 8.]\n",
      " [ 8.]\n",
      " [ 8.]\n",
      " [ 8.]\n",
      " [ 8.]\n",
      " [ 8.]\n",
      " [ 8.]\n",
      " [ 8.]\n",
      " [ 8.]\n",
      " [ 8.]\n",
      " [ 8.]\n",
      " [ 8.]\n",
      " [ 8.]\n",
      " [ 8.]\n",
      " [ 8.]\n",
      " [ 8.]\n",
      " [ 8.]\n",
      " [ 8.]\n",
      " [ 8.]\n",
      " [ 8.]\n",
      " [ 8.]\n",
      " [ 8.]\n",
      " [ 8.]\n",
      " [ 8.]\n",
      " [ 8.]\n",
      " [10.]\n",
      " [10.]\n",
      " [10.]\n",
      " [10.]\n",
      " [10.]\n",
      " [10.]\n",
      " [10.]\n",
      " [10.]\n",
      " [10.]\n",
      " [10.]\n",
      " [10.]\n",
      " [10.]\n",
      " [10.]\n",
      " [10.]\n",
      " [10.]\n",
      " [10.]\n",
      " [10.]\n",
      " [10.]\n",
      " [10.]\n",
      " [10.]\n",
      " [10.]\n",
      " [10.]\n",
      " [10.]\n",
      " [10.]\n",
      " [10.]\n",
      " [10.]\n",
      " [10.]\n",
      " [10.]\n",
      " [10.]\n",
      " [10.]\n",
      " [10.]\n",
      " [10.]\n",
      " [10.]\n",
      " [10.]\n",
      " [10.]\n",
      " [10.]\n",
      " [10.]\n",
      " [10.]\n",
      " [10.]\n",
      " [10.]\n",
      " [10.]]\n"
     ]
    }
   ],
   "source": [
    "y_train = y_train+5\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(387, 1)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shubham/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:463: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(16731, 1 - 1) = 0 components.\n",
      "  ChangedBehaviorWarning)\n",
      "/home/shubham/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:469: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
      "  warnings.warn(future_msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.76604407 0.75319512 0.7289348  ... 0.99860488 0.         0.        ]\n",
      " [0.529687   0.57813193 0.51568518 ... 0.99575397 0.         0.025     ]\n",
      " [0.41539965 0.45935107 0.40545591 ... 0.99593595 0.         0.05      ]\n",
      " ...\n",
      " [0.00423761 0.00373681 0.00344106 ... 0.10492539 1.         0.95      ]\n",
      " [0.00420819 0.00366722 0.00341799 ... 0.10493954 1.         0.975     ]\n",
      " [0.00266595 0.00311403 0.00209443 ... 0.05540256 1.         1.        ]]\n",
      "LinearDiscriminantAnalysis(n_components=11, priors=None, shrinkage=None,\n",
      "                           solver='svd', store_covariance=False, tol=0.0001)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shubham/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:399: RuntimeWarning: invalid value encountered in true_divide\n",
      "  S**2))[:self._max_components]\n"
     ]
    }
   ],
   "source": [
    "lda = LinearDiscriminantAnalysis(n_components=11)\n",
    "yval = y_train[:,1]\n",
    "lda.fit(X_train, yval)\n",
    "print(X_train)\n",
    "print(lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 0 is out of bounds for axis 1 with size 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-64-9c28556a6801>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainX_lda\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainX_lda\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainX_lda\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainX_lda\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainX_lda\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainX_lda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 0 is out of bounds for axis 1 with size 0"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 720x720 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainX_lda = lda.transform(X_train)\n",
    "colors = [\"#476A2A\", \"#7851B8\", \"#BD3430\", \"#4A2D4E\", \"#875525\",\n",
    "          \"#A83683\", \"#3E655E\",\"#5E666E\",\"#6E676E\",\"#7E685E\",\"#9E695E\"]\n",
    "print(trainX_lda)\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.xlim(trainX_lda[:, 0].min(), trainX_lda[:, 0].max())\n",
    "plt.ylim(trainX_lda[:, 1].min(), trainX_lda[:, 1].max())\n",
    "print(trainX_lda.shape)\n",
    "for i in range(len(trainX_lda)):\n",
    "    # actually plot the digits as text instead of using scatter\n",
    "    plt.text(trainX_lda[i, 0], trainX_lda[i, 1], str(y_train[i,0]),\n",
    "             color=colors[int(y_train[i,0])], fontdict={'weight': 'bold', 'size': 9})\n",
    "plt.xlabel(\"First Principal Component\")\n",
    "plt.ylabel(\"Second Principal Component\")\n",
    "plt.show(block=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "tsne = TSNE(random_state=21)\n",
    "# use fit_transform instead of fit, as TSNE has no transform method\n",
    "trainX_tsne = tsne.fit_transform(X_train)\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.xlim(trainX_tsne[:, 0].min(), trainX_tsne[:, 0].max())\n",
    "plt.ylim(trainX_tsne[:, 1].min(), trainX_tsne[:, 1].max())\n",
    "for i in range(len(trainX_tsne)):\n",
    "    # actually plot the digits as text instead of using scatter\n",
    "    plt.text(trainX_tsne[i, 0], trainX_tsne[i, 1], str(y_train[i]),\n",
    "            color=colors[int(y_train[i])], fontdict={'weight': 'bold', 'size': 9})\n",
    "plt.xlabel(\"t-SNE feature 0\")\n",
    "plt.ylabel(\"t-SNE feature 1\")\n",
    "plt.show(block=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(387, 2)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainX_tsne.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 2)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testX_tsne.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.concatenate((X_train,trainX_tsne),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.concatenate((X_test,testX_tsne),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = np.unique(data_new[:,7])\n",
    "print(l.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_data = pd.DataFrame({data_fn})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,10))\n",
    "cor = df.corr()\n",
    "sns.heatmap(cor, annot=True, cmap=plt.cm.Reds)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_fn[0])\n",
    "print(data_new[0][335:365])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(369,)\n"
     ]
    }
   ],
   "source": [
    "yval = y_train[:,0]\n",
    "print(yval.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(np.float64(X_train), yval, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(295, 16731)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(74,)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 20 folds for each of 1 candidates, totalling 20 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shubham/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py:281: UserWarning: The total space of parameters 1 is smaller than n_iter=10. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n",
      "[Parallel(n_jobs=5)]: Using backend LokyBackend with 5 concurrent workers.\n",
      "[Parallel(n_jobs=5)]: Done  20 out of  20 | elapsed:   11.7s finished\n"
     ]
    },
    {
     "ename": "XGBoostError",
     "evalue": "value 0 for Parameter num_class should be greater equal to 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mXGBoostError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-69-50fb0739aaea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0mX_ts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_ts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    737\u001b[0m             \u001b[0mrefit_start_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    738\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 739\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    740\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    741\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, callbacks)\u001b[0m\n\u001b[1;32m    730\u001b[0m                               \u001b[0mevals_result\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    731\u001b[0m                               \u001b[0mverbose_eval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxgb_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxgb_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 732\u001b[0;31m                               callbacks=callbacks)\n\u001b[0m\u001b[1;32m    733\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    734\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobjective\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb_options\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"objective\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/xgboost/training.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, learning_rates)\u001b[0m\n\u001b[1;32m    214\u001b[0m                            \u001b[0mevals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m                            \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m                            xgb_model=xgb_model, callbacks=callbacks)\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/xgboost/training.py\u001b[0m in \u001b[0;36m_train_internal\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks)\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;31m# Skip the first update if it is a recovery step.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mversion\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_rabit_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0mversion\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   1107\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1108\u001b[0m             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle, ctypes.c_int(iteration),\n\u001b[0;32m-> 1109\u001b[0;31m                                                     dtrain.handle))\n\u001b[0m\u001b[1;32m   1110\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1111\u001b[0m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36m_check_call\u001b[0;34m(ret)\u001b[0m\n\u001b[1;32m    174\u001b[0m     \"\"\"\n\u001b[1;32m    175\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mXGBoostError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpy_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_LIB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mXGBGetLastError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mXGBoostError\u001b[0m: value 0 for Parameter num_class should be greater equal to 1"
     ]
    }
   ],
   "source": [
    "xgb_model = xgb.XGBClassifier()#(xgb_model='best_grid.pkl')#xgb.train(loaded_params,xgb_model=)#\n",
    "\n",
    "parameters = {'nthread':[3], #when use hyperthread, xgboost may become slower\n",
    "              'objective':['multi:softmax'],\n",
    "              'learning_rate': [0.05], #so called `eta` value\n",
    "              'max_depth': [15],\n",
    "              'min_child_weight': [15],\n",
    "              'silent': [1],\n",
    "              'subsample': [0.8],\n",
    "              'colsample_bytree': [1.0],\n",
    "              'n_estimators': [100], #number of trees, change it to 1000 for better results\n",
    "              'missing':[-999],\n",
    "              'seed': [1337]}\n",
    "\n",
    "\n",
    "clf = RandomizedSearchCV(xgb_model, parameters, n_jobs=5, \n",
    "                   cv=20, \n",
    "                   scoring='accuracy',\n",
    "                   verbose=2, refit=True)\n",
    "X_tr = X_train\n",
    "X_ts = X_test\n",
    "\n",
    "clf.fit(X_tr, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_ts)\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "#xgb_model.fit(X_train, y_train)\n",
    "'''\n",
    "param_grid = {  }\n",
    "\n",
    "gs = GridSearchCV(\n",
    "        estimator=model,\n",
    "        param_grid=param_grid, \n",
    "        cv=cv, \n",
    "        n_jobs=-1, \n",
    "        scoring=scoring_fit,\n",
    "        verbose=2\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "#clf.fit(X_train, y_train,eval_set=[(X_train, y_train), (X_test, y_test)],eval_metric='logloss',verbose=True)\n",
    "\n",
    "#evals_result = clf.evals_result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.527"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(y_pred==y_test).sum()/len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "joblib.dump(clf.best_estimator_, 'part_grid.pkl')\n",
    "clf.save_model('best_model.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_params = joblib.load('best_grid.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred2 = loaded_params.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(y_pred2==y_pred).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(data=X_train, label=y_train)\n",
    "dvalid = xgb.DMatrix(data=X_test, label=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#params=loaded_params,\n",
    "params = {'nthread':[4], #when use hyperthread, xgboost may become slower\n",
    "              'objective':['multi:softmax'],\n",
    "              'learning_rate': [0.05], #so called `eta` value\n",
    "              #'max_depth': [6],\n",
    "              #'min_child_weight': [11],\n",
    "              #'silent': [1],\n",
    "              #'subsample': [0.8],\n",
    "              #'colsample_bytree': [0.7],\n",
    "              'n_estimators': [10] #number of trees, change it to 1000 for better results\n",
    "              #'missing':[-999],\n",
    "              'seed': [1337]\n",
    "             }\n",
    "\n",
    "mod = xgb.train(params= params,dtrain=dtrain,num_boost_round=10000,early_stopping_rounds=100,evals=[(dvalid,'valid'), (dtrain,'train')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for l in range(10):\n",
    "    data_new = []\n",
    "    data_fn = []\n",
    "    for k in range(10000):\n",
    "        b = data[10000*l+k][1]\n",
    "        for i in b.splitlines():\n",
    "            m = 0\n",
    "            a = []\n",
    "            c = []\n",
    "            for j in i.split('\\t'):\n",
    "                #print(m)\n",
    "                if(m!=1 and m!=2):\n",
    "                    a.append(float(j))\n",
    "                else:\n",
    "                    c.append(str(j))\n",
    "                m += 1\n",
    "        #print(a)\n",
    "        a = np.array(a)\n",
    "        c = np.array(c)\n",
    "        #print(type(a[0][6]))\n",
    "        #print(a)\n",
    "        data_fn.append(c)\n",
    "        data_new.append(a)\n",
    "        \n",
    "    data_fn = np.array(data_fn)\n",
    "    data_new = np.array(data_new)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(data_new[:,1:], data_new[:,0], test_size=0.1, random_state=42)\n",
    "    xg_train_1 = xgb.DMatrix(X_train, label=y_train)\n",
    "    xg_test = xgb.DMatrix(X_test, label=y_test)\n",
    "    \n",
    "    params = {'objective': 'multi:softmax', 'verbose': False, 'num_class' : 5, 'num_parallel_tree' : 10}\n",
    "\n",
    "    if i==0:\n",
    "        model_1 = xgb.train(params, xg_train_1, 30)\n",
    "        model_1.save_model('model_1.model')\n",
    "    else:\n",
    "        model_2_v2 = xgb.train(params, xg_train_2, 30, xgb_model='model_1.model')\n",
    "        model_2_v2.save_model('model_1.model')\n",
    "        print(np.sum(model_2_v2.predict(xg_test)== y_test)/len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xg_train_1 = xgb.DMatrix(X_train, label=y_train)\n",
    "xg_train_2 = xgb.DMatrix(X_train, label=y_train)\n",
    "xg_test = xgb.DMatrix(X_test, label=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'objective': 'multi:softmax', 'verbose': False, 'num_class' : 5, 'n_estimators' : 1}\n",
    "\n",
    "model_1 = xgb.train(params, xg_train_1, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1.save_model('model_1.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2_v1 = xgb.train(params, xg_train_2, 10)\n",
    "model_2_v2 = xgb.train(params, xg_train_2, 10, xgb_model='model_1.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.sum(model_1.predict(xg_test)== y_test))     # benchmark\n",
    "print(np.sum(model_2_v1.predict(xg_test)== y_test))  # \"before\"\n",
    "print(np.sum(model_2_v2.predict(xg_test)== y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_scikit = xgb.XGBClassifier(verbose=0,\n",
    "                               objective='multi:softmax',\n",
    "                               n_jobs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_scikit.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb.train(params=xgb_scikit.get_xgb_params, dtrain=dtrain, xgb_model=xgb_scikit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = LogisticRegression(random_state=0).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(reg.score(X_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(reg.coef_)\n",
    "print(reg.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = reg.predict(X_test)\n",
    "print(test_pred)\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss = np.sum(np.square(y_test-test_pred))\n",
    "test_loss = test_loss/250\n",
    "print(test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(897, 9)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.array(X_train)\n",
    "x_test = np.array(X_test)\n",
    "y_labeltest = np.array(y_test)\n",
    "y_label = np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 50\n",
    "train_loader = torch.utils.data.DataLoader(dataset = x_train,\n",
    "                                          batch_size = batch_size,\n",
    "                                          shuffle = False)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset = x_test,\n",
    "                                          batch_size = 1,\n",
    "                                          shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegressionModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LogisticRegressionModel,self).__init__()\n",
    "        self.lin1 = nn.Linear(9,200)\n",
    "        self.lin2 = nn.Linear(200,1000)\n",
    "        self.lin3 = nn.Linear(1000,5000)\n",
    "        self.lin4 = nn.Linear(5000,500)\n",
    "        self.lin5 = nn.Linear(500,100)\n",
    "        self.lin6 = nn.Linear(100,15)\n",
    "        self.act1 = nn.ReLU()\n",
    "        self.act2 = nn.Sigmoid()\n",
    "        #self.act3 = nn.Tanh()\n",
    "        #self.sof = nn.Softmax()\n",
    "        \n",
    "    def forward(self,x):\n",
    "        #batch, data = x\n",
    "        \n",
    "        out = self.lin1(x)\n",
    "        out = self.act1(out)\n",
    "        out = self.lin2(out)\n",
    "        out = self.act1(out)\n",
    "        out = self.lin3(out)\n",
    "        out = self.act1(out)\n",
    "        out = self.lin4(out)\n",
    "        out = self.act1(out)\n",
    "        #out = out + out2\n",
    "        out = self.lin5(out)\n",
    "        out = self.act1(out)\n",
    "        out = self.lin6(out)\n",
    "        out = self.act2(out)\n",
    "        '''\n",
    "        out = self.lin1(x)\n",
    "        out = self.act1(out)\n",
    "        out = self.lin2(out)\n",
    "        out = self.act1(out)\n",
    "        out = self.lin5(out)\n",
    "        out = self.act1(out)\n",
    "        out = self.lin6(out)\n",
    "        out = self.act2(out)\n",
    "        '''\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda')\n",
    "model = (LogisticRegressionModel().double()).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.functional.cross_entropy\n",
    "#criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3, weight_decay=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    loss_all = 0\n",
    "    i = 0\n",
    "    for data in train_loader:\n",
    "        '''\n",
    "        inputs = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(inputs)\n",
    "        #print(output.shape)\n",
    "        label = torch.LongTensor(y_label[i*100:(i+1)*100]).to(device)\n",
    "        #print(label.shape)\n",
    "        \n",
    "        #out_prob = nn.functional.softmax(output,dim=1)\n",
    "        #print(out_prob.shape)\n",
    "        #max_prob, pred = torch.max(out_prob,dim=1)\n",
    "        #print(pred.shape)\n",
    "        #pred = torch.reshape(pred, (-1, 1))\n",
    "        loss = criterion(output, label)\n",
    "        #print(output)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        '''\n",
    "        inputs = data.to('cuda')\n",
    "        #print(type(inputs))\n",
    "        #print(inputs)\n",
    "        labels = torch.LongTensor(np.array(y_label[i*50:(i+1)*50]-1)).to('cuda')\n",
    "        #print(labels)\n",
    "        i = i+1\n",
    "        \n",
    "    \n",
    "        outputs = model(inputs)\n",
    "        #print(outputs)\n",
    "        #print(outputs)\n",
    "        loss = criterion(outputs,labels)\n",
    "    \n",
    "        loss.backward()\n",
    "    \n",
    "        optimizer.step()\n",
    "        loss_all += loss\n",
    "        \n",
    "    return loss_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(train_loader):\n",
    "    model.eval()\n",
    "\n",
    "    predictions = []\n",
    "    labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data in train_loader:\n",
    "            data = data.to(device)\n",
    "            pred = model(data)\n",
    "            \n",
    "            pred = pred.detach().cpu().numpy()\n",
    "            #ed2 = ed2.detach().cpu().numpy()\n",
    "            label = data.y.detach().cpu().numpy()\n",
    "            pred = np.mean(pred,0)\n",
    "            predictions.append(pred)\n",
    "            labels.append(label)\n",
    "\n",
    "    predictions = np.hstack(predictions)\n",
    "    \n",
    "    #print(\"labels\")\n",
    "    labels = np.hstack(labels)\n",
    "    #print(labels)\n",
    "    #predictions = np.reshape(predictions,labels.shape)\n",
    "    #print(predictions)\n",
    "    return mse(labels, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#del model, optimizer, loss, outputs\n",
    "torch.cuda.empty_cache()\n",
    "CUDA_LAUNCH_BLOCKING=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 200, loss 42.056750207309236\n",
      "epoch 400, loss 41.585268040712954\n",
      "epoch 600, loss 40.69909879644\n",
      "epoch 800, loss 40.6164968236418\n",
      "epoch 1000, loss 40.43198604411577\n",
      "epoch 1200, loss 39.482983538838646\n",
      "epoch 1400, loss 40.05738268225399\n",
      "epoch 1600, loss 39.52473511382506\n",
      "epoch 1800, loss 39.07717954163045\n",
      "epoch 2000, loss 39.072278966039576\n",
      "epoch 2200, loss 39.36476827373336\n",
      "epoch 2400, loss 39.07671592027564\n",
      "epoch 2600, loss 38.093028145389724\n",
      "epoch 2800, loss 37.796836837856304\n",
      "epoch 3000, loss 38.772631639342485\n",
      "epoch 3200, loss 37.58194538674524\n",
      "epoch 3400, loss 37.560683564563696\n",
      "epoch 3600, loss 37.43872630951116\n",
      "epoch 3800, loss 37.295873138806805\n",
      "epoch 4000, loss 37.48838026958493\n",
      "epoch 4200, loss 37.26633309004693\n",
      "epoch 4400, loss 38.040684580249305\n",
      "epoch 4600, loss 36.96948280856105\n",
      "epoch 4800, loss 37.378055981868286\n",
      "epoch 5000, loss 37.382807192594484\n"
     ]
    }
   ],
   "source": [
    "optimizer.zero_grad()\n",
    "model.train()\n",
    "model.load_state_dict(torch.load('/home/shubham/log_5g.pkl'))\n",
    "for epoch in range(5000):\n",
    "    epoch += 1\n",
    "    \n",
    "    i = 0\n",
    "    loss = train(train_loader)\n",
    "    if epoch%200==0:\n",
    "        print('epoch {}, loss {}'.format(epoch, loss.data))\n",
    "        torch.save(model.state_dict(),'/home/shubham/log_5g.pkl')\n",
    "    '''\n",
    "    for data in train_loader:\n",
    "        inputs = data.to('cuda')\n",
    "        #print(type(inputs))\n",
    "        #print(inputs)\n",
    "        labels = torch.LongTensor(np.array(y_label[i*100:(i+1)*100]-1)).to('cuda')\n",
    "        #print(labels)\n",
    "        i = i+1\n",
    "        \n",
    "    \n",
    "        outputs = model(inputs)\n",
    "        #print(outputs)\n",
    "        #print(outputs)\n",
    "        loss = criterion(outputs,labels)\n",
    "    \n",
    "        loss.backward()\n",
    "    \n",
    "        optimizer.step()\n",
    "        # Logging\n",
    "        \n",
    "        if epoch%200==0:\n",
    "            print('epoch {}, loss {}'.format(epoch, loss.data))\n",
    "        if loss<1:\n",
    "            pass\n",
    "            torch.save(model.state_dict(),'/home/shubham/lin_5g.pkl')\n",
    "    \n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = []\n",
    "for data in test_loader:\n",
    "    l = model(data.to(device))\n",
    "    out_prob = nn.functional.softmax(l,dim=1)\n",
    "    #print(out_prob.shape)\n",
    "    max_prob, pred = torch.max(out_prob,dim=1)\n",
    "    #print(pred.shape)\n",
    "    labels.append((pred.cpu()).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = np.unique(y_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 7]\n",
      " [ 7]\n",
      " [14]\n",
      " [14]\n",
      " [13]\n",
      " [ 2]\n",
      " [10]\n",
      " [12]\n",
      " [13]\n",
      " [ 7]\n",
      " [13]\n",
      " [13]\n",
      " [14]\n",
      " [ 6]\n",
      " [10]\n",
      " [ 5]\n",
      " [14]\n",
      " [13]\n",
      " [13]\n",
      " [14]\n",
      " [10]\n",
      " [ 8]\n",
      " [ 7]\n",
      " [14]\n",
      " [13]\n",
      " [ 9]\n",
      " [ 6]\n",
      " [13]\n",
      " [11]\n",
      " [12]\n",
      " [ 5]\n",
      " [12]\n",
      " [11]\n",
      " [10]\n",
      " [11]\n",
      " [ 9]\n",
      " [11]\n",
      " [10]\n",
      " [ 7]\n",
      " [ 8]\n",
      " [11]\n",
      " [ 9]\n",
      " [ 9]\n",
      " [13]\n",
      " [13]\n",
      " [13]\n",
      " [13]\n",
      " [11]\n",
      " [11]\n",
      " [ 9]\n",
      " [11]\n",
      " [ 6]\n",
      " [13]\n",
      " [13]\n",
      " [14]\n",
      " [14]\n",
      " [14]\n",
      " [11]\n",
      " [14]\n",
      " [11]\n",
      " [13]\n",
      " [ 9]\n",
      " [13]\n",
      " [ 6]\n",
      " [14]\n",
      " [ 9]\n",
      " [ 9]\n",
      " [11]\n",
      " [ 8]\n",
      " [ 4]\n",
      " [ 6]\n",
      " [13]\n",
      " [ 7]\n",
      " [14]\n",
      " [11]\n",
      " [ 9]\n",
      " [11]\n",
      " [10]\n",
      " [13]\n",
      " [14]\n",
      " [14]\n",
      " [ 8]\n",
      " [11]\n",
      " [10]\n",
      " [11]\n",
      " [13]\n",
      " [11]\n",
      " [ 7]\n",
      " [ 8]\n",
      " [ 5]\n",
      " [14]\n",
      " [ 9]\n",
      " [ 9]\n",
      " [ 7]\n",
      " [13]\n",
      " [ 4]\n",
      " [14]\n",
      " [11]\n",
      " [11]\n",
      " [11]\n",
      " [14]\n",
      " [14]\n",
      " [ 7]\n",
      " [14]\n",
      " [ 6]\n",
      " [13]\n",
      " [11]\n",
      " [11]\n",
      " [ 9]\n",
      " [ 6]\n",
      " [13]\n",
      " [13]\n",
      " [14]\n",
      " [13]\n",
      " [13]\n",
      " [10]\n",
      " [ 7]\n",
      " [11]\n",
      " [12]\n",
      " [11]\n",
      " [ 7]\n",
      " [13]\n",
      " [ 6]\n",
      " [ 5]\n",
      " [11]\n",
      " [12]\n",
      " [11]\n",
      " [13]\n",
      " [11]\n",
      " [11]\n",
      " [ 9]\n",
      " [ 8]\n",
      " [ 5]\n",
      " [13]\n",
      " [14]\n",
      " [ 8]\n",
      " [ 9]\n",
      " [ 6]\n",
      " [11]\n",
      " [ 6]\n",
      " [11]\n",
      " [ 8]\n",
      " [11]\n",
      " [ 9]\n",
      " [ 6]\n",
      " [11]\n",
      " [ 9]\n",
      " [11]\n",
      " [14]\n",
      " [11]\n",
      " [11]\n",
      " [11]\n",
      " [10]\n",
      " [ 4]\n",
      " [14]\n",
      " [ 6]\n",
      " [13]\n",
      " [13]\n",
      " [13]\n",
      " [14]\n",
      " [ 9]\n",
      " [ 7]\n",
      " [11]\n",
      " [13]\n",
      " [13]\n",
      " [14]\n",
      " [13]\n",
      " [14]\n",
      " [ 6]\n",
      " [12]\n",
      " [11]\n",
      " [ 8]\n",
      " [14]\n",
      " [14]\n",
      " [13]\n",
      " [ 9]\n",
      " [ 2]\n",
      " [ 6]\n",
      " [12]\n",
      " [13]\n",
      " [ 6]\n",
      " [13]\n",
      " [13]\n",
      " [13]\n",
      " [11]\n",
      " [13]\n",
      " [14]\n",
      " [11]\n",
      " [13]\n",
      " [11]\n",
      " [11]\n",
      " [ 6]\n",
      " [ 9]\n",
      " [11]\n",
      " [14]\n",
      " [ 0]\n",
      " [11]\n",
      " [14]\n",
      " [11]\n",
      " [11]\n",
      " [ 8]\n",
      " [13]\n",
      " [14]\n",
      " [13]\n",
      " [ 9]\n",
      " [10]\n",
      " [13]\n",
      " [11]\n",
      " [11]\n",
      " [13]\n",
      " [12]\n",
      " [11]\n",
      " [14]\n",
      " [11]\n",
      " [14]\n",
      " [14]\n",
      " [14]\n",
      " [10]\n",
      " [ 5]\n",
      " [13]\n",
      " [ 6]\n",
      " [11]\n",
      " [11]\n",
      " [ 5]\n",
      " [11]]\n",
      "[ 1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12. 13. 14. 15.]\n"
     ]
    }
   ],
   "source": [
    "print(labels)\n",
    "print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = (y_labeltest==labels[:][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.02666666666666667\n"
     ]
    }
   ],
   "source": [
    "accuracy = acc.sum()/len(acc)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        index                                                  0\n",
      "0           1  0\\te791ac64-71be-11ea-bd9b-a3cc40581063\\tf0931...\n",
      "1           2  1\\td82bb79f-71be-11ea-bd9b-3b9845418535\\t92019...\n",
      "2           3  0\\td4d7ab5a-71be-11ea-bd9b-9165b2d9ddb1\\tfba32...\n",
      "3           4  1\\tc7759c19-71be-11ea-bd9b-e73978b2c4cd\\t57b07...\n",
      "4           5  0\\te282343f-71be-11ea-bd9b-dbf702df66ed\\t935a9...\n",
      "...       ...                                                ...\n",
      "99995   99996  1\\tcd7541ad-71be-11ea-bd9b-8500f8c9f638\\t25180...\n",
      "99996   99997  0\\tdfc0f140-71be-11ea-bd9b-45e74fc616b3\\t924d1...\n",
      "99997   99998  1\\te9762456-71be-11ea-bd9b-bf2346f28ea7\\t8d251...\n",
      "99998   99999  0\\tec537a35-71be-11ea-bd9b-3735fead3324\\t948ea...\n",
      "99999  100000  1\\te7422d44-71be-11ea-bd9b-719de7d8e7d3\\t41d52...\n",
      "\n",
      "[100000 rows x 2 columns]\n",
      "Epoch: 000, Loss: 120.41720\n",
      "Epoch: 001, Loss: 120.41618\n",
      "Epoch: 002, Loss: 120.41619\n",
      "Epoch: 003, Loss: 120.41605\n",
      "Epoch: 004, Loss: 120.41404\n",
      "Epoch: 005, Loss: 119.96582\n",
      "Epoch: 006, Loss: 119.79666\n",
      "Epoch: 007, Loss: 119.71512\n",
      "Epoch: 008, Loss: 119.45850\n",
      "Epoch: 009, Loss: 118.96179\n",
      "Epoch: 010, Loss: 118.78915\n",
      "Epoch: 011, Loss: 118.32539\n",
      "Epoch: 012, Loss: 120.40852\n",
      "Epoch: 013, Loss: 119.71514\n",
      "Epoch: 014, Loss: 120.37313\n",
      "Epoch: 015, Loss: 119.07869\n",
      "Epoch: 016, Loss: 117.36462\n",
      "Epoch: 017, Loss: 116.31190\n",
      "Epoch: 018, Loss: 115.42819\n",
      "Epoch: 019, Loss: 114.87521\n",
      "Epoch: 020, Loss: 114.78725\n",
      "Epoch: 021, Loss: 113.96677\n",
      "Epoch: 022, Loss: 113.55891\n",
      "Epoch: 023, Loss: 113.17519\n",
      "Epoch: 024, Loss: 112.72740\n",
      "Epoch: 025, Loss: 112.31223\n",
      "Epoch: 026, Loss: 112.75227\n",
      "Epoch: 027, Loss: 112.21088\n",
      "Epoch: 028, Loss: 111.22728\n",
      "Epoch: 029, Loss: 110.51714\n",
      "0.46\n",
      "        index                                                  0\n",
      "0      200001  1\\te4c67ed6-71be-11ea-bd9b-3de8565dd341\\t59df7...\n",
      "1      200002  2\\tc05ac334-71be-11ea-bd9b-6fd8cc302f6c\\tbce3d...\n",
      "2      200003  2\\tc4aba70b-71be-11ea-bd9b-5d5dcd1cc6f1\\t0b3d1...\n",
      "3      200004  2\\tbdbbaf17-71be-11ea-bd9b-7dc4c06d363b\\t1dfe6...\n",
      "4      200005  1\\td89fd6f4-71be-11ea-bd9b-172db112ef00\\t14000...\n",
      "...       ...                                                ...\n",
      "99995  299996  1\\tbf57d2a6-71be-11ea-bd9b-491f868698b2\\t9cf43...\n",
      "99996  299997  1\\tebcc6fa0-71be-11ea-bd9b-e75025792521\\t05b0d...\n",
      "99997  299998  2\\teb38bb9e-71be-11ea-bd9b-777fff8ddeaf\\t03f23...\n",
      "99998  299999  2\\td54b2d19-71be-11ea-bd9b-f3ac789dbe30\\te5e78...\n",
      "99999  300000  0\\te1ccedd7-71be-11ea-bd9b-dd5bbc584b87\\t85bcb...\n",
      "\n",
      "[100000 rows x 2 columns]\n",
      "Epoch: 000, Loss: 121.33340\n",
      "Epoch: 001, Loss: 120.21810\n",
      "Epoch: 002, Loss: 119.77948\n",
      "Epoch: 003, Loss: 119.25261\n",
      "Epoch: 004, Loss: 118.66161\n",
      "Epoch: 005, Loss: 118.14676\n",
      "Epoch: 006, Loss: 118.03342\n",
      "Epoch: 007, Loss: 117.85241\n",
      "Epoch: 008, Loss: 117.35894\n",
      "Epoch: 009, Loss: 117.08760\n",
      "Epoch: 010, Loss: 116.70084\n",
      "Epoch: 011, Loss: 116.30780\n",
      "Epoch: 012, Loss: 116.07033\n",
      "Epoch: 013, Loss: 115.62713\n",
      "Epoch: 014, Loss: 112.90125\n",
      "Epoch: 015, Loss: 110.62115\n",
      "Epoch: 016, Loss: 109.26962\n",
      "Epoch: 017, Loss: 108.70287\n",
      "Epoch: 018, Loss: 107.68350\n",
      "Epoch: 019, Loss: 106.41591\n",
      "Epoch: 020, Loss: 106.27009\n",
      "Epoch: 021, Loss: 105.86617\n",
      "Epoch: 022, Loss: 106.58453\n",
      "Epoch: 023, Loss: 105.99686\n",
      "Epoch: 024, Loss: 105.30105\n",
      "Epoch: 025, Loss: 105.97454\n",
      "Epoch: 026, Loss: 105.62911\n",
      "Epoch: 027, Loss: 104.26865\n",
      "Epoch: 028, Loss: 102.10218\n",
      "Epoch: 029, Loss: 100.72277\n",
      "0.462\n",
      "        index                                                  0\n",
      "0      500001  1\\tc9b070fb-71be-11ea-bd9b-eb0fc84bcc6f\\t7344a...\n",
      "1      500002  2\\td15e62c6-71be-11ea-bd9b-7dd5aac519e7\\td319a...\n",
      "2      500003  1\\tc54ddb08-71be-11ea-bd9b-372b95549621\\t551c9...\n",
      "3      500004  0\\tbdb1753c-71be-11ea-bd9b-89b2c3b1d460\\tbd1e0...\n",
      "4      500005  2\\tc293ea71-71be-11ea-bd9b-b1e7773e66b8\\t32223...\n",
      "...       ...                                                ...\n",
      "99995  599996  1\\tca1f5fdd-71be-11ea-bd9b-0f65444589fc\\t9c2b0...\n",
      "99996  599997  1\\tf058fd27-71be-11ea-bd9b-c1842bd4001b\\t17fc8...\n",
      "99997  599998  2\\tee589917-71be-11ea-bd9b-3b80c3974e47\\t3788f...\n",
      "99998  599999  0\\tbf4ed14a-71be-11ea-bd9b-dff7aa42f8bf\\t078a9...\n",
      "99999  600000  0\\teb47d630-71be-11ea-bd9b-b34cb5b9f2b1\\t6391e...\n",
      "\n",
      "[100000 rows x 2 columns]\n",
      "Epoch: 000, Loss: 123.29637\n",
      "Epoch: 001, Loss: 120.42106\n",
      "Epoch: 002, Loss: 120.41476\n",
      "Epoch: 003, Loss: 120.41315\n",
      "Epoch: 004, Loss: 120.40983\n",
      "Epoch: 005, Loss: 120.39887\n",
      "Epoch: 006, Loss: 120.37354\n",
      "Epoch: 007, Loss: 120.32828\n"
     ]
    }
   ],
   "source": [
    "pca = IncrementalPCA(n_components=100,batch_size=1000)\n",
    "batch_size = 100\n",
    "\n",
    "for x in df:\n",
    "    print(x)\n",
    "    data_new = []\n",
    "    data_fn = []\n",
    "    data = np.array(x)\n",
    "    for k in range(10000):\n",
    "        b = data[k][1]\n",
    "        for i in b.splitlines():\n",
    "            m = 0\n",
    "            a = []\n",
    "            c = []\n",
    "            for j in i.split('\\t'):\n",
    "                #print(m)\n",
    "                if(m!=1 and m!=2):\n",
    "                    a.append(np.float32(j))\n",
    "                else:\n",
    "                    c.append(str(j))\n",
    "                m += 1\n",
    "        #print(a)\n",
    "        a = np.array(a,dtype=np.float32)\n",
    "        c = np.array(c)\n",
    "        #print(type(a[0][6]))\n",
    "        #print(a)\n",
    "        data_fn.append(c)\n",
    "        data_new.append(a)\n",
    "        \n",
    "    data_fn = np.array(data_fn)\n",
    "    data_new = np.array(data_new,dtype=np.float32)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(data_new[:,1:], data_new[:,0], test_size=0.1, random_state=42)\n",
    "    \n",
    "    scaler = MinMaxScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.fit_transform(X_test)\n",
    "    pca.fit(X_train)\n",
    "    data_train = pca.transform(X_train)\n",
    "    data_test = pca.transform(X_test)\n",
    "    data_train = np.asarray(data_train,np.float32)\n",
    "    data_test = np.asarray(data_test,np.float32)\n",
    "    \n",
    "    train_loader = torch.utils.data.DataLoader(dataset = data_train,\n",
    "                                              batch_size = batch_size,\n",
    "                                              shuffle = False)\n",
    "\n",
    "    test_loader = torch.utils.data.DataLoader(dataset = data_test,\n",
    "                                              batch_size = 1,\n",
    "                                              shuffle = False)\n",
    "    \n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    \n",
    "    \n",
    "    for epoch in range(30):\n",
    "        loss = train(train_loader)\n",
    "\n",
    "        #val_acc = evaluate(val_loader)    \n",
    "        #test_acc = evaluate(test_loader)\n",
    "\n",
    "\n",
    "        if epoch%1==0:\n",
    "            #learning_rate *= 0.9\n",
    "            #optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "            print('Epoch: {:03d}, Loss: {:.5f}'.\n",
    "              format(epoch, loss))\n",
    "            torch.save(model.state_dict(),'m_pca_dl.pkl')\n",
    "        \n",
    "    labels = []\n",
    "    for data_t in test_loader:\n",
    "        l = model(data_t.to(device))\n",
    "        out_prob = nn.functional.softmax(l,dim=1)\n",
    "        #print(out_prob.shape)\n",
    "        max_prob, pred = torch.max(out_prob,dim=1)\n",
    "        #print(pred.shape)\n",
    "        labels.append((pred.cpu()).numpy())\n",
    "    \n",
    "    labels = np.array(labels)\n",
    "    acc = (y_test==labels[:][0])\n",
    "    accuracy = acc.sum()/len(acc)\n",
    "    print(accuracy)\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = []\n",
    "for data_t in test_loader:\n",
    "        l = model(data_t.to(device))\n",
    "        out_prob = nn.functional.softmax(l,dim=1)\n",
    "        #print(out_prob.shape)\n",
    "        max_prob, pred = torch.max(out_prob,dim=1)\n",
    "        #print(pred.shape)\n",
    "        labels.append((pred.cpu()).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2]\n"
     ]
    }
   ],
   "source": [
    "l = np.unique(labels)\n",
    "print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        index                                                  0\n",
      "0     4450001  0\\tec9453fc-71be-11ea-bd9b-77a3ec3bc16e\\t6656b...\n",
      "1     4450002  1\\tee333741-71be-11ea-bd9b-9175cbb93d31\\tf850a...\n",
      "2     4450003  2\\tda11b64d-71be-11ea-bd9b-17c929c6afd4\\t779ec...\n",
      "3     4450004  1\\tc885fb3f-71be-11ea-bd9b-b72732336108\\tfb8a1...\n",
      "4     4450005  1\\tdef6c312-71be-11ea-bd9b-dfc3e02c7ef0\\tabb7f...\n",
      "...       ...                                                ...\n",
      "9995  4459996  0\\te9203b3f-71be-11ea-bd9b-5360d26ca68a\\t4cdc1...\n",
      "9996  4459997  2\\tcd206a9f-71be-11ea-bd9b-79bfbad4f32c\\t4b198...\n",
      "9997  4459998  2\\tdf3bbbab-71be-11ea-bd9b-991edd2db6cc\\t74561...\n",
      "9998  4459999  2\\tdd95858c-71be-11ea-bd9b-c7e88b642e92\\t3879a...\n",
      "9999  4460000  1\\te02b4b8d-71be-11ea-bd9b-05a4de643fd8\\t69614...\n",
      "\n",
      "[10000 rows x 2 columns]\n",
      "0.544\n",
      "0\n",
      "[[100.]\n",
      " [100.]\n",
      " [  0.]\n",
      " ...\n",
      " [100.]\n",
      " [100.]\n",
      " [  0.]]\n",
      "Epoch: 000, Loss: 12.26409\n",
      "Epoch: 001, Loss: 12.26408\n",
      "Epoch: 002, Loss: 12.26407\n",
      "Epoch: 003, Loss: 12.26406\n",
      "Epoch: 004, Loss: 12.26404\n",
      "Epoch: 005, Loss: 12.26403\n",
      "Epoch: 006, Loss: 12.26402\n",
      "Epoch: 007, Loss: 12.26401\n",
      "Epoch: 008, Loss: 12.26400\n",
      "Epoch: 009, Loss: 12.26399\n",
      "Epoch: 010, Loss: 12.26398\n",
      "Epoch: 011, Loss: 12.26397\n",
      "Epoch: 012, Loss: 12.26396\n",
      "Epoch: 013, Loss: 12.26395\n",
      "Epoch: 014, Loss: 12.26394\n",
      "Epoch: 015, Loss: 12.26393\n",
      "Epoch: 016, Loss: 12.26392\n",
      "Epoch: 017, Loss: 12.26391\n",
      "Epoch: 018, Loss: 12.26390\n",
      "Epoch: 019, Loss: 12.26389\n",
      "0.473\n",
      "        index                                                  0\n",
      "0     4460001  2\\td7f1954e-71be-11ea-bd9b-c7059ef081bf\\tcf20c...\n",
      "1     4460002  2\\tbc5122ac-71be-11ea-bd9b-3dd042fdc92d\\t669d9...\n",
      "2     4460003  1\\tc8580d13-71be-11ea-bd9b-717a4cd19bd2\\t7ceac...\n",
      "3     4460004  2\\te4004858-71be-11ea-bd9b-a7bcc542af13\\ta1ecc...\n",
      "4     4460005  1\\tde3ee524-71be-11ea-bd9b-dd954cd1ef1b\\t4bd4c...\n",
      "...       ...                                                ...\n",
      "9995  4469996  2\\td5d4cffc-71be-11ea-bd9b-21bcb992f241\\t38be6...\n",
      "9996  4469997  0\\tdc86865c-71be-11ea-bd9b-d753835bf62e\\t78187...\n",
      "9997  4469998  1\\te82c17d7-71be-11ea-bd9b-c958722425d1\\t32637...\n",
      "9998  4469999  1\\tcbd1f174-71be-11ea-bd9b-05c7f39f3928\\td35d2...\n",
      "9999  4470000  3\\tc1b6aa57-71be-11ea-bd9b-75721b019743\\td1d69...\n",
      "\n",
      "[10000 rows x 2 columns]\n",
      "0.551\n",
      "1\n",
      "[[200.]\n",
      " [100.]\n",
      " [100.]\n",
      " ...\n",
      " [100.]\n",
      " [100.]\n",
      " [  0.]]\n",
      "Epoch: 000, Loss: 12.28210\n",
      "Epoch: 001, Loss: 12.28208\n",
      "Epoch: 002, Loss: 12.28207\n",
      "Epoch: 003, Loss: 12.28206\n",
      "Epoch: 004, Loss: 12.28205\n",
      "Epoch: 005, Loss: 12.28203\n",
      "Epoch: 006, Loss: 12.28202\n",
      "Epoch: 007, Loss: 12.28201\n",
      "Epoch: 008, Loss: 12.28200\n",
      "Epoch: 009, Loss: 12.28199\n",
      "Epoch: 010, Loss: 12.28197\n",
      "Epoch: 011, Loss: 12.28196\n",
      "Epoch: 012, Loss: 12.28195\n",
      "Epoch: 013, Loss: 12.28194\n",
      "Epoch: 014, Loss: 12.28193\n",
      "Epoch: 015, Loss: 12.28191\n",
      "Epoch: 016, Loss: 12.28190\n",
      "Epoch: 017, Loss: 12.28189\n",
      "Epoch: 018, Loss: 12.28187\n",
      "Epoch: 019, Loss: 12.28186\n",
      "0.232\n",
      "        index                                                  0\n",
      "0     4470001  2\\tcfae8ff8-71be-11ea-bd9b-0996a111fa28\\ta31de...\n",
      "1     4470002  1\\tebbfed54-71be-11ea-bd9b-2d1864670341\\t0ae8a...\n",
      "2     4470003  2\\tc7342713-71be-11ea-bd9b-77252c75e078\\t724a6...\n",
      "3     4470004  2\\te8245003-71be-11ea-bd9b-df43d4192d97\\t5bb28...\n",
      "4     4470005  2\\te577585a-71be-11ea-bd9b-0b0bd77f580e\\td46be...\n",
      "...       ...                                                ...\n",
      "9995  4479996  2\\td0463b6e-71be-11ea-bd9b-29a73a6c80d3\\tab387...\n",
      "9996  4479997  0\\tbdb93dcb-71be-11ea-bd9b-3d8f2e97a649\\t4e23b...\n",
      "9997  4479998  2\\tbce4af52-71be-11ea-bd9b-51bf7a2eccb9\\tf0df2...\n",
      "9998  4479999  1\\tee0bb211-71be-11ea-bd9b-bf0a15077a2b\\tc9a17...\n",
      "9999  4480000  1\\tefe4427c-71be-11ea-bd9b-4bc5f226e81a\\t06a6a...\n",
      "\n",
      "[10000 rows x 2 columns]\n",
      "0.551\n",
      "2\n",
      "[[200.]\n",
      " [200.]\n",
      " [200.]\n",
      " ...\n",
      " [200.]\n",
      " [  0.]\n",
      " [100.]]\n",
      "Epoch: 000, Loss: 12.25941\n",
      "Epoch: 001, Loss: 12.25939\n",
      "Epoch: 002, Loss: 12.25938\n",
      "Epoch: 003, Loss: 12.25936\n",
      "Epoch: 004, Loss: 12.25935\n",
      "Epoch: 005, Loss: 12.25933\n",
      "Epoch: 006, Loss: 12.25932\n",
      "Epoch: 007, Loss: 12.25930\n",
      "Epoch: 008, Loss: 12.25929\n",
      "Epoch: 009, Loss: 12.25928\n",
      "Epoch: 010, Loss: 12.25926\n",
      "Epoch: 011, Loss: 12.25924\n",
      "Epoch: 012, Loss: 12.25923\n",
      "Epoch: 013, Loss: 12.25922\n",
      "Epoch: 014, Loss: 12.25920\n",
      "Epoch: 015, Loss: 12.25919\n",
      "Epoch: 016, Loss: 12.25917\n",
      "Epoch: 017, Loss: 12.25916\n",
      "Epoch: 018, Loss: 12.25914\n",
      "Epoch: 019, Loss: 12.25913\n",
      "0.245\n",
      "        index                                                  0\n",
      "0     4480001  2\\tedaec452-71be-11ea-bd9b-af7754c2e43e\\taaa82...\n",
      "1     4480002  1\\tcc4aa3c4-71be-11ea-bd9b-7ff3772245a6\\t11601...\n",
      "2     4480003  0\\te19cdc95-71be-11ea-bd9b-4b3f08b69c0e\\ta2b25...\n",
      "3     4480004  0\\td33aeaf5-71be-11ea-bd9b-cba48653971a\\t1595c...\n",
      "4     4480005  2\\te0d76995-71be-11ea-bd9b-a768fdbf7215\\ta8eba...\n",
      "...       ...                                                ...\n",
      "9995  4489996  1\\tebef1322-71be-11ea-bd9b-95fec05a138f\\t9a5c3...\n",
      "9996  4489997  1\\te4fe577b-71be-11ea-bd9b-ff2808c286ee\\t4dcc9...\n",
      "9997  4489998  1\\tbcc5dce2-71be-11ea-bd9b-6324ba1ea3d5\\t37de1...\n",
      "9998  4489999  4\\tdd2d9c22-71be-11ea-bd9b-5527733c41ab\\t5b24f...\n",
      "9999  4490000  0\\tbf08c834-71be-11ea-bd9b-c12ac3bc8242\\t989b4...\n",
      "\n",
      "[10000 rows x 2 columns]\n",
      "0.559\n",
      "3\n",
      "[[100.]\n",
      " [100.]\n",
      " [100.]\n",
      " ...\n",
      " [200.]\n",
      " [200.]\n",
      " [100.]]\n",
      "Epoch: 000, Loss: 12.27796\n",
      "Epoch: 001, Loss: 12.27794\n",
      "Epoch: 002, Loss: 12.27793\n",
      "Epoch: 003, Loss: 12.27792\n",
      "Epoch: 004, Loss: 12.27790\n",
      "Epoch: 005, Loss: 12.27789\n",
      "Epoch: 006, Loss: 12.27787\n",
      "Epoch: 007, Loss: 12.27786\n",
      "Epoch: 008, Loss: 12.27785\n",
      "Epoch: 009, Loss: 12.27783\n",
      "Epoch: 010, Loss: 12.27782\n",
      "Epoch: 011, Loss: 12.27780\n",
      "Epoch: 012, Loss: 12.27779\n",
      "Epoch: 013, Loss: 12.27778\n",
      "Epoch: 014, Loss: 12.27776\n",
      "Epoch: 015, Loss: 12.27775\n",
      "Epoch: 016, Loss: 12.27774\n",
      "Epoch: 017, Loss: 12.27772\n",
      "Epoch: 018, Loss: 12.27771\n",
      "Epoch: 019, Loss: 12.27770\n",
      "0.258\n",
      "        index                                                  0\n",
      "0     4490001  0\\tbd869494-71be-11ea-bd9b-8ddbc8d34c8d\\t9657b...\n",
      "1     4490002  0\\tdc57fc69-71be-11ea-bd9b-bd2d7594b872\\t9a2d8...\n",
      "2     4490003  3\\tce40cf67-71be-11ea-bd9b-3f8e156a8fc9\\t2e238...\n",
      "3     4490004  1\\tccbf1108-71be-11ea-bd9b-fb7ad19b4ef6\\tb9ace...\n",
      "4     4490005  1\\tc3402fc8-71be-11ea-bd9b-055b95e4c169\\t44118...\n",
      "...       ...                                                ...\n",
      "9995  4499996  0\\te7fddc02-71be-11ea-bd9b-1b121db34629\\tfd67d...\n",
      "9996  4499997  3\\tdbd75afd-71be-11ea-bd9b-e5768f1d44fa\\t8c6df...\n",
      "9997  4499998  2\\tdb2b6301-71be-11ea-bd9b-29cc5590c662\\t5e82f...\n",
      "9998  4499999  0\\td95d815e-71be-11ea-bd9b-43ac030d668e\\tcf966...\n",
      "9999  4500000  2\\tde15b25a-71be-11ea-bd9b-91dab9ab63fd\\t4fddc...\n",
      "\n",
      "[10000 rows x 2 columns]\n",
      "0.539\n",
      "4\n",
      "[[  0.]\n",
      " [  0.]\n",
      " [200.]\n",
      " ...\n",
      " [200.]\n",
      " [200.]\n",
      " [200.]]\n",
      "Epoch: 000, Loss: 12.23849\n",
      "Epoch: 001, Loss: 12.23848\n",
      "Epoch: 002, Loss: 12.23847\n",
      "Epoch: 003, Loss: 12.23846\n",
      "Epoch: 004, Loss: 12.23844\n",
      "Epoch: 005, Loss: 12.23843\n",
      "Epoch: 006, Loss: 12.23842\n",
      "Epoch: 007, Loss: 12.23841\n",
      "Epoch: 008, Loss: 12.23840\n",
      "Epoch: 009, Loss: 12.23839\n",
      "Epoch: 010, Loss: 12.23837\n",
      "Epoch: 011, Loss: 12.23836\n",
      "Epoch: 012, Loss: 12.23835\n",
      "Epoch: 013, Loss: 12.23834\n",
      "Epoch: 014, Loss: 12.23833\n",
      "Epoch: 015, Loss: 12.23831\n",
      "Epoch: 016, Loss: 12.23830\n",
      "Epoch: 017, Loss: 12.23829\n",
      "Epoch: 018, Loss: 12.23828\n",
      "Epoch: 019, Loss: 12.23827\n",
      "0.461\n",
      "        index                                                  0\n",
      "0     5400001  1\\tbee8bd3f-71be-11ea-bd9b-8d62cf12b125\\tc407c...\n",
      "1     5400002  2\\tc059b221-71be-11ea-bd9b-bbe9219d630d\\t56de9...\n",
      "2     5400003  1\\te0024013-71be-11ea-bd9b-eb32234683be\\t929e9...\n",
      "3     5400004  2\\tcfce9ae8-71be-11ea-bd9b-a390e18c5b88\\t390cd...\n",
      "4     5400005  1\\td49857f2-71be-11ea-bd9b-9bc7c2a08bef\\t13751...\n",
      "...       ...                                                ...\n",
      "9995  5409996  0\\tbe0c66d3-71be-11ea-bd9b-a7bb09193da4\\t3975b...\n",
      "9996  5409997  0\\tc53f342c-71be-11ea-bd9b-0558dd8acc6e\\t1f2dd...\n",
      "9997  5409998  1\\tcc5049fb-71be-11ea-bd9b-3fa77735acb3\\t236b9...\n",
      "9998  5409999  1\\tdeff006b-71be-11ea-bd9b-6947d7b35a60\\tcf30b...\n",
      "9999  5410000  1\\td07f4d3d-71be-11ea-bd9b-a79bf254faa4\\t187eb...\n",
      "\n",
      "[10000 rows x 2 columns]\n",
      "0.553\n",
      "5\n",
      "[[200.]\n",
      " [100.]\n",
      " [100.]\n",
      " ...\n",
      " [100.]\n",
      " [100.]\n",
      " [  0.]]\n",
      "Epoch: 000, Loss: 12.24834\n",
      "Epoch: 001, Loss: 12.24833\n",
      "Epoch: 002, Loss: 12.24832\n",
      "Epoch: 003, Loss: 12.24830\n",
      "Epoch: 004, Loss: 12.24829\n",
      "Epoch: 005, Loss: 12.24827\n",
      "Epoch: 006, Loss: 12.24826\n",
      "Epoch: 007, Loss: 12.24825\n",
      "Epoch: 008, Loss: 12.24823\n",
      "Epoch: 009, Loss: 12.24822\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 010, Loss: 12.24820\n",
      "Epoch: 011, Loss: 12.24819\n",
      "Epoch: 012, Loss: 12.24817\n",
      "Epoch: 013, Loss: 12.24816\n",
      "Epoch: 014, Loss: 12.24815\n",
      "Epoch: 015, Loss: 12.24813\n",
      "Epoch: 016, Loss: 12.24812\n",
      "Epoch: 017, Loss: 12.24811\n",
      "Epoch: 018, Loss: 12.24809\n",
      "Epoch: 019, Loss: 12.24808\n",
      "0.422\n",
      "        index                                                  0\n",
      "0     5410001  2\\td4c2ea84-71be-11ea-bd9b-619e28e694a8\\t34983...\n",
      "1     5410002  1\\tc4a2cd7f-71be-11ea-bd9b-eb95d8835d07\\td4c68...\n",
      "2     5410003  1\\te9820ab8-71be-11ea-bd9b-01429f926c9c\\td8633...\n",
      "3     5410004  1\\td4ac54d9-71be-11ea-bd9b-f501a7d52e5e\\tec15b...\n",
      "4     5410005  2\\td3289b2d-71be-11ea-bd9b-630e66e7536f\\t23726...\n",
      "...       ...                                                ...\n",
      "9995  5419996  1\\tdc9490a3-71be-11ea-bd9b-2bb4ce56eb3c\\ta59c7...\n",
      "9996  5419997  0\\tc52fcb12-71be-11ea-bd9b-1b48ec74ddc8\\t704a6...\n",
      "9997  5419998  2\\tdbc83f30-71be-11ea-bd9b-b990479363c7\\t31e22...\n",
      "9998  5419999  1\\te35e3bec-71be-11ea-bd9b-3908c0cd87db\\tc0f56...\n",
      "9999  5420000  1\\tc049fb15-71be-11ea-bd9b-ff5b81ea06c7\\te0cf4...\n",
      "\n",
      "[10000 rows x 2 columns]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-b8ac024ea32f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloop_i\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0mmodel_2_v2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxg_train_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxgb_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'xgb_dl.model'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0mmodel_2_v2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'xgb_dl.model'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0mlabels_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_2_v2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxg_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/xgboost/training.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, learning_rates)\u001b[0m\n\u001b[1;32m    214\u001b[0m                            \u001b[0mevals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m                            \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m                            xgb_model=xgb_model, callbacks=callbacks)\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/xgboost/training.py\u001b[0m in \u001b[0;36m_train_internal\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks)\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;31m# Skip the first update if it is a recovery step.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mversion\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_rabit_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0mversion\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   1107\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1108\u001b[0m             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle, ctypes.c_int(iteration),\n\u001b[0;32m-> 1109\u001b[0;31m                                                     dtrain.handle))\n\u001b[0m\u001b[1;32m   1110\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1111\u001b[0m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "pca = IncrementalPCA(n_components=100,batch_size=1000)\n",
    "batch_size = 1000\n",
    "loop_i = 0\n",
    "\n",
    "#model.load_state_dict(torch.load('m_pca_dl.pkl'))\n",
    "#model.eval()\n",
    "\n",
    "for x in df:\n",
    "    print(x)\n",
    "    data_new = []\n",
    "    data_fn = []\n",
    "    data = np.array(x)\n",
    "    for k in range(len(data)):\n",
    "        b = data[k][1]\n",
    "        for i in b.splitlines():\n",
    "            m = 0\n",
    "            a = []\n",
    "            c = []\n",
    "            for j in i.split('\\t'):\n",
    "                #print(m)\n",
    "                if(m!=1 and m!=2):\n",
    "                    a.append(np.float32(j))\n",
    "                else:\n",
    "                    c.append(str(j))\n",
    "                m += 1\n",
    "        #print(a)\n",
    "        a = np.array(a,dtype=np.float32)\n",
    "        c = np.array(c)\n",
    "        #print(type(a[0][6]))\n",
    "        #print(a)\n",
    "        data_fn.append(c)\n",
    "        data_new.append(a)\n",
    "        \n",
    "    data_fn = np.array(data_fn)\n",
    "    data_new = np.array(data_new,dtype=np.float32)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(data_new[:,1:], data_new[:,0], test_size=0.1, random_state=42)\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    laskmd\n",
    "    '''\n",
    "    xg_train_1 = xgb.DMatrix(X_train, label=y_train)\n",
    "    xg_test = xgb.DMatrix(X_test, label=y_test)\n",
    "    \n",
    "    params = {'objective': 'multi:softmax', 'verbose': False, 'num_class' : 5, 'num_parallel_tree' : 15, 'learning_rate': 0.05, #so called `eta` value\n",
    "              'max_depth': 15,\n",
    "              'min_child_weight': 15,\n",
    "              'silent': 1,\n",
    "              'subsample': 0.7,\n",
    "              'colsample_bytree': 1.0,\n",
    "              'n_estimators': 15,\n",
    "               'nthread' : 3}\n",
    "\n",
    "    if loop_i==0:\n",
    "        model_2_v2 = xgb.train(params, xg_train_1, 10, xgb_model='model_1.model')\n",
    "        model_2_v2.save_model('xgb_dl.model')\n",
    "        labels_test = model_2_v2.predict(xg_test)\n",
    "        labels_train = model_2_v2.predict(xg_train_1)\n",
    "        print(np.sum(labels_test == y_test)/len(y_test))\n",
    "        print(loop_i)\n",
    "    else:\n",
    "        model_2_v2 = xgb.train(params, xg_train_1, 10, xgb_model='xgb_dl.model')\n",
    "        model_2_v2.save_model('xgb_dl.model')\n",
    "        labels_test = model_2_v2.predict(xg_test)\n",
    "        labels_train = model_2_v2.predict(xg_train_1)\n",
    "        print(np.sum(labels_test == y_test)/len(y_test))\n",
    "        print(loop_i)\n",
    "        \n",
    "    \n",
    "    scaler = MinMaxScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.fit_transform(X_test)\n",
    "    pca.fit(X_train)\n",
    "    data_train = pca.transform(X_train)\n",
    "    data_test = pca.transform(X_test)\n",
    "    data_train = np.asarray(data_train,np.float32)\n",
    "    data_test = np.asarray(data_test,np.float32)\n",
    "    \n",
    "    labels_test = np.reshape((100*labels_test),(-1,1))\n",
    "    labels_train = np.reshape((100*labels_train),(-1,1))\n",
    "    print(labels_train)\n",
    "    X_train_new = np.concatenate((data_train,labels_train),axis=1)\n",
    "    X_test_new = np.concatenate((data_test,labels_test),axis=1)\n",
    "    \n",
    "    \n",
    "    train_loader = torch.utils.data.DataLoader(dataset = X_train_new,\n",
    "                                              batch_size = batch_size,\n",
    "                                              shuffle = False)\n",
    "\n",
    "    test_loader = torch.utils.data.DataLoader(dataset = X_test_new,\n",
    "                                              batch_size = 1,\n",
    "                                              shuffle = False)\n",
    "    \n",
    "    \n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    \n",
    "    \n",
    "    for epoch in range(20):\n",
    "        loss = train(train_loader)\n",
    "\n",
    "        #val_acc = evaluate(val_loader)    \n",
    "        #test_acc = evaluate(test_loader)\n",
    "\n",
    "\n",
    "        if epoch%1==0:\n",
    "            #learning_rate *= 0.9\n",
    "            #optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "            print('Epoch: {:03d}, Loss: {:.5f}'.\n",
    "              format(epoch, loss))\n",
    "            torch.save(model.state_dict(),'m_xgb_dl.pkl')\n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "    labels_train = []\n",
    "    labels_test = []\n",
    "    for data_t in test_loader:\n",
    "        l_test = model(data_t.to(device))\n",
    "        out_prob = nn.functional.softmax(l_test,dim=1)\n",
    "        #print(out_prob.shape)\n",
    "        max_prob, pred = torch.max(out_prob,dim=1)\n",
    "        #print(pred.shape)\n",
    "        labels_test.append((pred.cpu()).numpy())\n",
    "        \n",
    "#     for data_tr in train_loader:\n",
    "#         l_train = model(data_tr.to(device))\n",
    "#         out_prob = nn.functional.softmax(l_train,dim=1)\n",
    "#         #print(out_prob.shape)\n",
    "#         max_prob, pred = torch.max(out_prob,dim=1)\n",
    "#         #print(pred.shape)\n",
    "#         labels_train.append((pred.cpu()).numpy())\n",
    "    \n",
    "    labels_test = np.array(labels_test)\n",
    "    #labels_train = np.array(labels_train)\n",
    "    acc = (y_test==labels_test[:][0])\n",
    "    accuracy = acc.sum()/len(acc)\n",
    "    print(accuracy)\n",
    "    \n",
    "    '''\n",
    "    XGBoost Implementation on Increased feature space\n",
    "    '''\n",
    "        \n",
    "    if loop_i%5==1:\n",
    "        model_2_v2.save_model('xgb_dl_5.model')\n",
    "    \n",
    "    loop_i +=1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       index                                                  0\n",
      "0     910001  1\\tf09394ff-71be-11ea-bd9b-b54447a684cd\\t758ee...\n",
      "1     910002  2\\td14e3680-71be-11ea-bd9b-1f6bc8584e88\\t5ee2e...\n",
      "2     910003  1\\ted3a30a1-71be-11ea-bd9b-2be82ae2c928\\t78269...\n",
      "3     910004  1\\te21149f8-71be-11ea-bd9b-bfd7854a282a\\t36b04...\n",
      "4     910005  2\\teba16822-71be-11ea-bd9b-fd4eb9bf2656\\tc51b8...\n",
      "...      ...                                                ...\n",
      "9995  919996  2\\tcb5b148c-71be-11ea-bd9b-1d1526707f11\\te2062...\n",
      "9996  919997  1\\tbd9c666f-71be-11ea-bd9b-2170d0052670\\t0479e...\n",
      "9997  919998  1\\te19a446f-71be-11ea-bd9b-6f1c8ea1c4d1\\t66437...\n",
      "9998  919999  1\\td5b1b6b3-71be-11ea-bd9b-4562d52b522d\\teac7d...\n",
      "9999  920000  0\\tda476bcb-71be-11ea-bd9b-e5ac74d0e5fc\\t957e9...\n",
      "\n",
      "[10000 rows x 2 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shubham/anaconda3/lib/python3.7/site-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " ...\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]]\n",
      "[1. 1. 0. ... 0. 1. 0.]\n",
      "0.4543\n",
      "       index                                                  0\n",
      "0     920001  3\\tcf445ca8-71be-11ea-bd9b-91fd9213d01f\\t0c732...\n",
      "1     920002  2\\td0a32934-71be-11ea-bd9b-558ae84e35d0\\t7f542...\n",
      "2     920003  0\\td0cbbf62-71be-11ea-bd9b-d5685ec8ae76\\t2906c...\n",
      "3     920004  2\\tdcc6c354-71be-11ea-bd9b-17657e833bb8\\t1f11c...\n",
      "4     920005  1\\tbf5820f5-71be-11ea-bd9b-4de4d3eb1f89\\t019a8...\n",
      "...      ...                                                ...\n",
      "9995  929996  2\\tbd8ed234-71be-11ea-bd9b-7b37e813cb05\\t030ee...\n",
      "9996  929997  0\\td663a20a-71be-11ea-bd9b-451f2190ccf1\\tf0983...\n",
      "9997  929998  2\\te6611b6d-71be-11ea-bd9b-c1ab61507b3a\\t78350...\n",
      "9998  929999  1\\tbca97aed-71be-11ea-bd9b-2f4f64755c25\\t9943b...\n",
      "9999  930000  2\\te75d5621-71be-11ea-bd9b-d1476f207792\\tca561...\n",
      "\n",
      "[10000 rows x 2 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shubham/anaconda3/lib/python3.7/site-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " ...\n",
      " [2. 0.]\n",
      " [2. 0.]\n",
      " [1. 0.]]\n",
      "[1. 1. 0. ... 0. 2. 0.]\n",
      "0.4506\n",
      "       index                                                  0\n",
      "0     930001  0\\tdb37984b-71be-11ea-bd9b-19f754862e05\\t98118...\n",
      "1     930002  0\\tcf89c968-71be-11ea-bd9b-91899970c247\\t19420...\n",
      "2     930003  4\\tcd18f085-71be-11ea-bd9b-b77f895b4518\\t3676d...\n",
      "3     930004  1\\tddd41549-71be-11ea-bd9b-9d7e823fb3d6\\t75f57...\n",
      "4     930005  0\\teb8c32b5-71be-11ea-bd9b-c1f7d75a6354\\t450fc...\n",
      "...      ...                                                ...\n",
      "9995  939996  0\\td7ec1672-71be-11ea-bd9b-790614041d40\\t8dfb3...\n",
      "9996  939997  2\\te3ba8caf-71be-11ea-bd9b-cfc110566642\\t9410e...\n",
      "9997  939998  2\\tee62d2b4-71be-11ea-bd9b-49456c82debd\\t98eb1...\n",
      "9998  939999  1\\te795078a-71be-11ea-bd9b-95fc4d0ddac0\\t91fd8...\n",
      "9999  940000  1\\te99655e8-71be-11ea-bd9b-dba695895435\\t4c1ff...\n",
      "\n",
      "[10000 rows x 2 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shubham/anaconda3/lib/python3.7/site-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " ...\n",
      " [4. 0.]\n",
      " [2. 0.]\n",
      " [0. 1.]]\n",
      "[0. 0. 1. ... 4. 0. 1.]\n",
      "0.2634\n",
      "       index                                                  0\n",
      "0     940001  1\\td2bc4468-71be-11ea-bd9b-077377b180c9\\t5d9f1...\n",
      "1     940002  1\\td590e928-71be-11ea-bd9b-7362c78e61d6\\t9b346...\n",
      "2     940003  1\\tbf98abac-71be-11ea-bd9b-d142cd8a15bb\\t24fc8...\n",
      "3     940004  4\\tef2a67eb-71be-11ea-bd9b-a38a2c8a2683\\t36faf...\n",
      "4     940005  1\\te14b8897-71be-11ea-bd9b-f934f5e7f019\\t5c1f6...\n",
      "...      ...                                                ...\n",
      "9995  949996  0\\tdfeeb853-71be-11ea-bd9b-cf9536548003\\t5c792...\n",
      "9996  949997  1\\te11adb99-71be-11ea-bd9b-35840327f776\\t6827d...\n",
      "9997  949998  4\\te55b1d27-71be-11ea-bd9b-ab6c611e8d53\\t35cc8...\n",
      "9998  949999  2\\tc50140f8-71be-11ea-bd9b-af02dc12528b\\t5833e...\n",
      "9999  950000  0\\td1b582d1-71be-11ea-bd9b-19d000de99c5\\t02023...\n",
      "\n",
      "[10000 rows x 2 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shubham/anaconda3/lib/python3.7/site-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-a06d5ee8cff6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0mbst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBooster\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'nthread'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'xgb_dl.model'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m     \u001b[0mlabels_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxg_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0mscaler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMinMaxScaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, data, output_margin, ntree_limit, pred_leaf, pred_contribs, approx_contribs, pred_interactions, validate_features)\u001b[0m\n\u001b[1;32m   1290\u001b[0m                                           \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_uint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mntree_limit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1291\u001b[0m                                           \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbyref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlength\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1292\u001b[0;31m                                           ctypes.byref(preds)))\n\u001b[0m\u001b[1;32m   1293\u001b[0m         \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mctypes2numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlength\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1294\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpred_leaf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "pca = IncrementalPCA(n_components=100,batch_size=1000)\n",
    "batch_size = 100\n",
    "loop_i = 0\n",
    "\n",
    "model.load_state_dict(torch.load('m_xgb_dl.pkl'))\n",
    "model.eval()\n",
    "\n",
    "for x in df:\n",
    "    print(x)\n",
    "    data_new = []\n",
    "    data_fn = []\n",
    "    data = np.array(x)\n",
    "    for k in range(len(data)):\n",
    "        b = data[k][1]\n",
    "        for i in b.splitlines():\n",
    "            m = 0\n",
    "            a = []\n",
    "            c = []\n",
    "            for j in i.split('\\t'):\n",
    "                #print(m)\n",
    "                if(m!=1 and m!=2):\n",
    "                    a.append(np.float32(j))\n",
    "                else:\n",
    "                    c.append(str(j))\n",
    "                m += 1\n",
    "        #print(a)\n",
    "        a = np.array(a,dtype=np.float32)\n",
    "        c = np.array(c)\n",
    "        #print(type(a[0][6]))\n",
    "        #print(a)\n",
    "        data_fn.append(c)\n",
    "        data_new.append(a)\n",
    "        \n",
    "    data_fn = np.array(data_fn)\n",
    "    data_new = np.array(data_new,dtype=np.float32)\n",
    "    \n",
    "    #X_train, X_test, y_train, y_test = train_test_split(data_new[:,1:], data_new[:,0], test_size=1.0, random_state=42)\n",
    "    X_test = data_new[:,1:]\n",
    "    y_test = data_new[:,0]\n",
    "    \n",
    "    '''\n",
    "    laskmd\n",
    "    '''\n",
    "    #xg_train_1 = xgb.DMatrix(X_train, label=y_train)\n",
    "    xg_test = xgb.DMatrix(X_test, label=y_test)\n",
    "    \n",
    "    params = {'objective': 'multi:softmax', 'verbose': False, 'num_class' : 5, 'num_parallel_tree' : 15, 'learning_rate': 0.05, #so called `eta` value\n",
    "              'max_depth': 15,\n",
    "              'min_child_weight': 15,\n",
    "              'silent': 1,\n",
    "              'subsample': 0.7,\n",
    "              'colsample_bytree': 1.0,\n",
    "              'n_estimators': 15,\n",
    "               'nthread' : 3}\n",
    "    \n",
    "    '''\n",
    "    if loop_i==0:\n",
    "        model_2_v2 = xgb.train(params, xg_train_1, 10, xgb_model='model_1.model')\n",
    "        model_2_v2.save_model('xgb_dl.model')\n",
    "        labels_test = model_2_v2.predict(xg_test)\n",
    "        labels_train = model_2_v2.predict(xg_train_1)\n",
    "        print(np.sum(labels_test == y_test)/len(y_test))\n",
    "        print(loop_i)\n",
    "    else:\n",
    "        model_2_v2 = xgb.train(params, xg_train_1, 10, xgb_model='xgb_dl.model')\n",
    "        model_2_v2.save_model('xgb_dl.model')\n",
    "        labels_test = model_2_v2.predict(xg_test)\n",
    "        labels_train = model_2_v2.predict(xg_train_1)\n",
    "        print(np.sum(labels_test == y_test)/len(y_test))\n",
    "        print(loop_i)\n",
    "        \n",
    "    '''\n",
    "    bst = xgb.Booster({'nthread': 3})\n",
    "    bst.load_model('xgb_dl.model')\n",
    "    labels_test = bst.predict(xg_test)\n",
    "    \n",
    "    scaler = MinMaxScaler()\n",
    "    #X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.fit_transform(X_test)\n",
    "    pca.fit(X_test)\n",
    "    #data_train = pca.transform(X_train)\n",
    "    data_test = pca.transform(X_test)\n",
    "    #data_train = np.asarray(data_train,np.float32)\n",
    "    data_test = np.asarray(data_test,np.float32)\n",
    "    \n",
    "    labels_test2 = np.reshape((100*labels_test),(-1,1))\n",
    "    #labels_train = np.reshape((100*labels_train),(-1,1))\n",
    "    #print(labels_train)\n",
    "    #X_train_new = np.concatenate((data_train,labels_train),axis=1)\n",
    "    X_test_new = np.concatenate((data_test,labels_test2),axis=1)\n",
    "    \n",
    "    \n",
    "    #train_loader = torch.utils.data.DataLoader(dataset = X_train_new,\n",
    "     #                                         batch_size = batch_size,\n",
    "     #                                         shuffle = False)\n",
    "\n",
    "    test_loader = torch.utils.data.DataLoader(dataset = X_test_new,\n",
    "                                              batch_size = 1000,\n",
    "                                              shuffle = False)\n",
    "    \n",
    "    \n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    for epoch in range(20):\n",
    "        loss = train(train_loader)\n",
    "\n",
    "        #val_acc = evaluate(val_loader)    \n",
    "        #test_acc = evaluate(test_loader)\n",
    "\n",
    "\n",
    "        if epoch%1==0:\n",
    "            #learning_rate *= 0.9\n",
    "            #optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "            print('Epoch: {:03d}, Loss: {:.5f}'.\n",
    "              format(epoch, loss))\n",
    "            torch.save(model.state_dict(),'m_xgb_dl.pkl')\n",
    "        \n",
    "    '''\n",
    "    \n",
    "    \n",
    "    labels_train = []\n",
    "    label_test = []\n",
    "    label_final = []\n",
    "    sloop = 0\n",
    "    for data_t in test_loader:\n",
    "        l_test = model(data_t.to('cuda'))\n",
    "        out_prob = nn.functional.softmax(l_test,dim=1)\n",
    "        #print(out_prob.shape)\n",
    "        max_prob, pred = torch.max(out_prob,dim=1)\n",
    "        #print(pred.shape)\n",
    "        lab_val = (pred.cpu()).numpy()\n",
    "        label_test.append(lab_val)\n",
    "        \n",
    "        #print(lab_test)\n",
    "        #print(lab_test)\n",
    "    \n",
    "    label_test = np.reshape(label_test,(-1,1))\n",
    "    labels_test = np.reshape(labels_test,(-1,1))\n",
    "    lab_test = np.concatenate((labels_test,label_test),axis=1)\n",
    "    print(lab_test)\n",
    "    \n",
    "    for z in range(len(lab_test)):\n",
    "        label_final.append(np.random.choice(lab_test[z], 1, p=[0.5,0.5])[0])\n",
    "        #print(label_final)\n",
    "        \n",
    "#     for data_tr in train_loader:\n",
    "#         l_train = model(data_tr.to(device))\n",
    "#         out_prob = nn.functional.softmax(l_train,dim=1)\n",
    "#         #print(out_prob.shape)\n",
    "#         max_prob, pred = torch.max(out_prob,dim=1)\n",
    "#         #print(pred.shape)\n",
    "#         labels_train.append((pred.cpu()).numpy())\n",
    "    \n",
    "    \n",
    "    label_final = np.array(label_final)\n",
    "    #labels_train = np.array(labels_train)\n",
    "\n",
    "    \n",
    "    print(label_final)\n",
    "    acc = (y_test==label_final[:][0])\n",
    "    accuracy = acc.sum()/len(acc)\n",
    "    print(accuracy)\n",
    "    \n",
    "    '''\n",
    "    XGBoost Implementation on Increased feature space\n",
    "    '''\n",
    "        \n",
    "    #if loop_i%5==1:\n",
    "    #    model_2_v2.save_model('xgb_dl_5.model')\n",
    "    \n",
    "    loop_i +=1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Timestamp', 'Longitude', 'Latitude', 'Speed', 'Operatorname', 'CellID',\n",
       "       'NetworkMode', 'RSRP', 'RSRQ', 'SNR', 'CQI', 'RSSI', 'DL_bitrate',\n",
       "       'UL_bitrate', 'State', 'PINGAVG', 'PINGMIN', 'PINGMAX', 'PINGSTDEV',\n",
       "       'PINGLOSS', 'CELLHEX', 'NODEHEX', 'LACHEX', 'RAWCELLID', 'NRxRSRP',\n",
       "       'NRxRSRQ'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(x):\n",
    "    \"\"\" If the value is a string, then remove currency symbol and delimiters\n",
    "    otherwise, the value is numeric and can be converted\n",
    "    \"\"\"\n",
    "    if isinstance(x, str):\n",
    "        #x_old = x\n",
    "        #x = x.replace('-', '0')\n",
    "        try:\n",
    "            x = np.float64(x)\n",
    "        except:    \n",
    "            x = np.nan\n",
    "    return(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_d = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Speed</th>\n",
       "      <th>RSRP</th>\n",
       "      <th>RSRQ</th>\n",
       "      <th>SNR</th>\n",
       "      <th>CQI</th>\n",
       "      <th>RSSI</th>\n",
       "      <th>DL_bitrate</th>\n",
       "      <th>UL_bitrate</th>\n",
       "      <th>NRxRSRP</th>\n",
       "      <th>NRxRSRQ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>-80.0</td>\n",
       "      <td>278.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>-2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>-80.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-97.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>-82.0</td>\n",
       "      <td>279.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>-97.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>-13.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>-82.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>-2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>-13.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>-82.0</td>\n",
       "      <td>1048.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>-2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1117</th>\n",
       "      <td>24.0</td>\n",
       "      <td>-90.0</td>\n",
       "      <td>-11.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>-66.0</td>\n",
       "      <td>4698.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>-83.0</td>\n",
       "      <td>-3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1118</th>\n",
       "      <td>24.0</td>\n",
       "      <td>-93.0</td>\n",
       "      <td>-12.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>-66.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-84.0</td>\n",
       "      <td>-2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1119</th>\n",
       "      <td>24.0</td>\n",
       "      <td>-93.0</td>\n",
       "      <td>-12.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>-66.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>-84.0</td>\n",
       "      <td>-2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1120</th>\n",
       "      <td>24.0</td>\n",
       "      <td>-90.0</td>\n",
       "      <td>-14.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>-66.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-83.0</td>\n",
       "      <td>-2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1121</th>\n",
       "      <td>24.0</td>\n",
       "      <td>-90.0</td>\n",
       "      <td>-14.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>-66.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-83.0</td>\n",
       "      <td>-2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1122 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Speed  RSRP  RSRQ   SNR   CQI  RSSI  DL_bitrate  UL_bitrate  NRxRSRP  \\\n",
       "0       1.0 -99.0 -10.0   7.0  14.0 -80.0       278.0         6.0    -99.0   \n",
       "1       1.0 -99.0 -10.0  10.0  14.0 -80.0         0.0         0.0    -97.0   \n",
       "2       1.0 -99.0 -10.0  10.0  13.0 -82.0       279.0         8.0    -97.0   \n",
       "3       1.0 -99.0 -13.0  10.0  13.0 -82.0         0.0         6.0    -99.0   \n",
       "4       1.0 -99.0 -13.0  10.0  13.0 -82.0      1048.0         9.0    -99.0   \n",
       "...     ...   ...   ...   ...   ...   ...         ...         ...      ...   \n",
       "1117   24.0 -90.0 -11.0  -1.0  14.0 -66.0      4698.0       300.0    -83.0   \n",
       "1118   24.0 -93.0 -12.0  -1.0  14.0 -66.0         0.0         0.0    -84.0   \n",
       "1119   24.0 -93.0 -12.0  -1.0  14.0 -66.0         7.0        64.0    -84.0   \n",
       "1120   24.0 -90.0 -14.0   1.0  14.0 -66.0         0.0         0.0    -83.0   \n",
       "1121   24.0 -90.0 -14.0   1.0  14.0 -66.0         0.0         0.0    -83.0   \n",
       "\n",
       "      NRxRSRQ  \n",
       "0        -2.0  \n",
       "1         0.0  \n",
       "2         0.0  \n",
       "3        -2.0  \n",
       "4        -2.0  \n",
       "...       ...  \n",
       "1117     -3.0  \n",
       "1118     -2.0  \n",
       "1119     -2.0  \n",
       "1120     -2.0  \n",
       "1121     -2.0  \n",
       "\n",
       "[1122 rows x 10 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_d.drop(['PINGAVG','PINGMIN','PINGMAX','PINGSTDEV','PINGLOSS','State','NODEHEX','LACHEX','RAWCELLID'\n",
    "          ,'Timestamp','Longitude','Latitude','Operatorname','CellID','CELLHEX','NetworkMode'],axis=1,inplace=True)\n",
    "#df_d = df_d[df_d.SNR.apply(lambda x: (x).isnumeric())].set_index('SNR')\n",
    "#df_d = df_d.replace(to_replace= ' -', value= np.nan, regex=True)\n",
    "#x = df_d[df_d.SNR.str.isnumeric()]\n",
    "#df_d['SNR'] = df_d['SNR'].apply(clean_data).astype('float')\n",
    "for cols in df_d.columns:\n",
    "    df_d[cols] = df_d[cols].apply(clean_data).astype('float')\n",
    "df_d.dropna(inplace=True)\n",
    "df_d.reset_index(inplace=True)\n",
    "df_d.drop(['index'],axis=1,inplace=True)\n",
    "df_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.float64'>\n"
     ]
    }
   ],
   "source": [
    "print(type(df_d['SNR'][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        7.0\n",
       "1       10.0\n",
       "2       10.0\n",
       "3       10.0\n",
       "4       10.0\n",
       "        ... \n",
       "1117    -1.0\n",
       "1118    -1.0\n",
       "1119    -1.0\n",
       "1120     1.0\n",
       "1121     1.0\n",
       "Name: SNR, Length: 1122, dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_d['SNR']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Speed</th>\n",
       "      <th>Operatorname</th>\n",
       "      <th>CellID</th>\n",
       "      <th>NetworkMode</th>\n",
       "      <th>RSRP</th>\n",
       "      <th>RSRQ</th>\n",
       "      <th>SNR</th>\n",
       "      <th>...</th>\n",
       "      <th>PINGMIN</th>\n",
       "      <th>PINGMAX</th>\n",
       "      <th>PINGSTDEV</th>\n",
       "      <th>PINGLOSS</th>\n",
       "      <th>CELLHEX</th>\n",
       "      <th>NODEHEX</th>\n",
       "      <th>LACHEX</th>\n",
       "      <th>RAWCELLID</th>\n",
       "      <th>NRxRSRP</th>\n",
       "      <th>NRxRSRQ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019.11.28_07.27.57</td>\n",
       "      <td>-8.388193</td>\n",
       "      <td>51.935608</td>\n",
       "      <td>0</td>\n",
       "      <td>B</td>\n",
       "      <td>12</td>\n",
       "      <td>5G</td>\n",
       "      <td>-102</td>\n",
       "      <td>-10</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>C</td>\n",
       "      <td>A81B</td>\n",
       "      <td>9CBA</td>\n",
       "      <td>11016972</td>\n",
       "      <td>-102.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019.11.28_07.27.57</td>\n",
       "      <td>-8.388269</td>\n",
       "      <td>51.935542</td>\n",
       "      <td>1</td>\n",
       "      <td>B</td>\n",
       "      <td>12</td>\n",
       "      <td>5G</td>\n",
       "      <td>-102</td>\n",
       "      <td>-10</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>C</td>\n",
       "      <td>A81B</td>\n",
       "      <td>9CBA</td>\n",
       "      <td>11016972</td>\n",
       "      <td>-102.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019.11.28_07.27.58</td>\n",
       "      <td>-8.388269</td>\n",
       "      <td>51.935542</td>\n",
       "      <td>1</td>\n",
       "      <td>B</td>\n",
       "      <td>12</td>\n",
       "      <td>5G</td>\n",
       "      <td>-102</td>\n",
       "      <td>-10</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>C</td>\n",
       "      <td>A81B</td>\n",
       "      <td>9CBA</td>\n",
       "      <td>11016972</td>\n",
       "      <td>-102.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019.11.28_07.27.59</td>\n",
       "      <td>-8.388269</td>\n",
       "      <td>51.935542</td>\n",
       "      <td>1</td>\n",
       "      <td>B</td>\n",
       "      <td>12</td>\n",
       "      <td>5G</td>\n",
       "      <td>-102</td>\n",
       "      <td>-10</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>C</td>\n",
       "      <td>A81B</td>\n",
       "      <td>9CBA</td>\n",
       "      <td>11016972</td>\n",
       "      <td>-101.0</td>\n",
       "      <td>-3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019.11.28_07.28.00</td>\n",
       "      <td>-8.388269</td>\n",
       "      <td>51.935542</td>\n",
       "      <td>1</td>\n",
       "      <td>B</td>\n",
       "      <td>12</td>\n",
       "      <td>5G</td>\n",
       "      <td>-102</td>\n",
       "      <td>-10</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>C</td>\n",
       "      <td>A81B</td>\n",
       "      <td>9CBA</td>\n",
       "      <td>11016972</td>\n",
       "      <td>-101.0</td>\n",
       "      <td>-3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1893</th>\n",
       "      <td>2019.11.28_08.01.59</td>\n",
       "      <td>-8.483033</td>\n",
       "      <td>51.898677</td>\n",
       "      <td>24</td>\n",
       "      <td>B</td>\n",
       "      <td>11</td>\n",
       "      <td>5G</td>\n",
       "      <td>-90</td>\n",
       "      <td>-11</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>B</td>\n",
       "      <td>A9AA</td>\n",
       "      <td>9CBA</td>\n",
       "      <td>11119115</td>\n",
       "      <td>-83.0</td>\n",
       "      <td>-3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1894</th>\n",
       "      <td>2019.11.28_08.02.00</td>\n",
       "      <td>-8.483033</td>\n",
       "      <td>51.898677</td>\n",
       "      <td>24</td>\n",
       "      <td>B</td>\n",
       "      <td>11</td>\n",
       "      <td>5G</td>\n",
       "      <td>-93</td>\n",
       "      <td>-12</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>B</td>\n",
       "      <td>A9AA</td>\n",
       "      <td>9CBA</td>\n",
       "      <td>11119115</td>\n",
       "      <td>-84.0</td>\n",
       "      <td>-2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1895</th>\n",
       "      <td>2019.11.28_08.02.01</td>\n",
       "      <td>-8.483033</td>\n",
       "      <td>51.898677</td>\n",
       "      <td>24</td>\n",
       "      <td>B</td>\n",
       "      <td>11</td>\n",
       "      <td>5G</td>\n",
       "      <td>-93</td>\n",
       "      <td>-12</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>B</td>\n",
       "      <td>A9AA</td>\n",
       "      <td>9CBA</td>\n",
       "      <td>11119115</td>\n",
       "      <td>-84.0</td>\n",
       "      <td>-2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1896</th>\n",
       "      <td>2019.11.28_08.02.02</td>\n",
       "      <td>-8.483033</td>\n",
       "      <td>51.898677</td>\n",
       "      <td>24</td>\n",
       "      <td>B</td>\n",
       "      <td>11</td>\n",
       "      <td>5G</td>\n",
       "      <td>-90</td>\n",
       "      <td>-14</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>B</td>\n",
       "      <td>A9AA</td>\n",
       "      <td>9CBA</td>\n",
       "      <td>11119115</td>\n",
       "      <td>-83.0</td>\n",
       "      <td>-2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1897</th>\n",
       "      <td>2019.11.28_08.02.03</td>\n",
       "      <td>-8.483033</td>\n",
       "      <td>51.898677</td>\n",
       "      <td>24</td>\n",
       "      <td>B</td>\n",
       "      <td>11</td>\n",
       "      <td>5G</td>\n",
       "      <td>-90</td>\n",
       "      <td>-14</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>B</td>\n",
       "      <td>A9AA</td>\n",
       "      <td>9CBA</td>\n",
       "      <td>11119115</td>\n",
       "      <td>-83.0</td>\n",
       "      <td>-2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1898 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Timestamp  Longitude   Latitude  Speed Operatorname  CellID  \\\n",
       "0     2019.11.28_07.27.57  -8.388193  51.935608      0            B      12   \n",
       "1     2019.11.28_07.27.57  -8.388269  51.935542      1            B      12   \n",
       "2     2019.11.28_07.27.58  -8.388269  51.935542      1            B      12   \n",
       "3     2019.11.28_07.27.59  -8.388269  51.935542      1            B      12   \n",
       "4     2019.11.28_07.28.00  -8.388269  51.935542      1            B      12   \n",
       "...                   ...        ...        ...    ...          ...     ...   \n",
       "1893  2019.11.28_08.01.59  -8.483033  51.898677     24            B      11   \n",
       "1894  2019.11.28_08.02.00  -8.483033  51.898677     24            B      11   \n",
       "1895  2019.11.28_08.02.01  -8.483033  51.898677     24            B      11   \n",
       "1896  2019.11.28_08.02.02  -8.483033  51.898677     24            B      11   \n",
       "1897  2019.11.28_08.02.03  -8.483033  51.898677     24            B      11   \n",
       "\n",
       "     NetworkMode  RSRP  RSRQ   SNR  ... PINGMIN PINGMAX  PINGSTDEV  PINGLOSS  \\\n",
       "0             5G  -102   -10   8.0  ...       -       -          -         -   \n",
       "1             5G  -102   -10   8.0  ...       -       -          -         -   \n",
       "2             5G  -102   -10   8.0  ...       -       -          -         -   \n",
       "3             5G  -102   -10   3.0  ...       -       -          -         -   \n",
       "4             5G  -102   -10   3.0  ...       -       -          -         -   \n",
       "...          ...   ...   ...   ...  ...     ...     ...        ...       ...   \n",
       "1893          5G   -90   -11  -1.0  ...       -       -          -         -   \n",
       "1894          5G   -93   -12  -1.0  ...       -       -          -         -   \n",
       "1895          5G   -93   -12  -1.0  ...       -       -          -         -   \n",
       "1896          5G   -90   -14   1.0  ...       -       -          -         -   \n",
       "1897          5G   -90   -14   1.0  ...       -       -          -         -   \n",
       "\n",
       "     CELLHEX NODEHEX LACHEX RAWCELLID NRxRSRP NRxRSRQ  \n",
       "0          C    A81B   9CBA  11016972  -102.0    -1.0  \n",
       "1          C    A81B   9CBA  11016972  -102.0    -1.0  \n",
       "2          C    A81B   9CBA  11016972  -102.0    -1.0  \n",
       "3          C    A81B   9CBA  11016972  -101.0    -3.0  \n",
       "4          C    A81B   9CBA  11016972  -101.0    -3.0  \n",
       "...      ...     ...    ...       ...     ...     ...  \n",
       "1893       B    A9AA   9CBA  11119115   -83.0    -3.0  \n",
       "1894       B    A9AA   9CBA  11119115   -84.0    -2.0  \n",
       "1895       B    A9AA   9CBA  11119115   -84.0    -2.0  \n",
       "1896       B    A9AA   9CBA  11119115   -83.0    -2.0  \n",
       "1897       B    A9AA   9CBA  11119115   -83.0    -2.0  \n",
       "\n",
       "[1898 rows x 26 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_d.drop(['CQI'],axis=1)\n",
    "y_train = df_d['CQI']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Speed</th>\n",
       "      <th>RSRP</th>\n",
       "      <th>RSRQ</th>\n",
       "      <th>SNR</th>\n",
       "      <th>RSSI</th>\n",
       "      <th>DL_bitrate</th>\n",
       "      <th>UL_bitrate</th>\n",
       "      <th>NRxRSRP</th>\n",
       "      <th>NRxRSRQ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>-80.0</td>\n",
       "      <td>278.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>-2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>-80.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-97.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>-82.0</td>\n",
       "      <td>279.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>-97.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>-13.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>-82.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>-2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>-13.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>-82.0</td>\n",
       "      <td>1048.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>-2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1117</th>\n",
       "      <td>24.0</td>\n",
       "      <td>-90.0</td>\n",
       "      <td>-11.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-66.0</td>\n",
       "      <td>4698.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>-83.0</td>\n",
       "      <td>-3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1118</th>\n",
       "      <td>24.0</td>\n",
       "      <td>-93.0</td>\n",
       "      <td>-12.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-66.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-84.0</td>\n",
       "      <td>-2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1119</th>\n",
       "      <td>24.0</td>\n",
       "      <td>-93.0</td>\n",
       "      <td>-12.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-66.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>-84.0</td>\n",
       "      <td>-2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1120</th>\n",
       "      <td>24.0</td>\n",
       "      <td>-90.0</td>\n",
       "      <td>-14.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-66.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-83.0</td>\n",
       "      <td>-2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1121</th>\n",
       "      <td>24.0</td>\n",
       "      <td>-90.0</td>\n",
       "      <td>-14.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-66.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-83.0</td>\n",
       "      <td>-2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1122 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Speed  RSRP  RSRQ   SNR  RSSI  DL_bitrate  UL_bitrate  NRxRSRP  NRxRSRQ\n",
       "0       1.0 -99.0 -10.0   7.0 -80.0       278.0         6.0    -99.0     -2.0\n",
       "1       1.0 -99.0 -10.0  10.0 -80.0         0.0         0.0    -97.0      0.0\n",
       "2       1.0 -99.0 -10.0  10.0 -82.0       279.0         8.0    -97.0      0.0\n",
       "3       1.0 -99.0 -13.0  10.0 -82.0         0.0         6.0    -99.0     -2.0\n",
       "4       1.0 -99.0 -13.0  10.0 -82.0      1048.0         9.0    -99.0     -2.0\n",
       "...     ...   ...   ...   ...   ...         ...         ...      ...      ...\n",
       "1117   24.0 -90.0 -11.0  -1.0 -66.0      4698.0       300.0    -83.0     -3.0\n",
       "1118   24.0 -93.0 -12.0  -1.0 -66.0         0.0         0.0    -84.0     -2.0\n",
       "1119   24.0 -93.0 -12.0  -1.0 -66.0         7.0        64.0    -84.0     -2.0\n",
       "1120   24.0 -90.0 -14.0   1.0 -66.0         0.0         0.0    -83.0     -2.0\n",
       "1121   24.0 -90.0 -14.0   1.0 -66.0         0.0         0.0    -83.0     -2.0\n",
       "\n",
       "[1122 rows x 9 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(897, 9)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       14.0\n",
       "1       14.0\n",
       "2       13.0\n",
       "3       13.0\n",
       "4       13.0\n",
       "        ... \n",
       "1117    14.0\n",
       "1118    14.0\n",
       "1119    14.0\n",
       "1120    14.0\n",
       "1121    14.0\n",
       "Name: CQI, Length: 1122, dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_reg = Lasso(alpha=5)\n",
    "lasso_reg.fit(X_train,y_train)\n",
    "pred = lasso_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = np.sqrt(np.square(np.subtract(y_test,pred)).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.822092054388608"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "coeff = lasso_reg.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.00000000e+00,  3.17580866e-02,  0.00000000e+00,  1.11934043e-01,\n",
       "        3.38608607e-03,  2.61523025e-05, -1.69285468e-04,  0.00000000e+00,\n",
       "       -9.82316920e-05])"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coeff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
